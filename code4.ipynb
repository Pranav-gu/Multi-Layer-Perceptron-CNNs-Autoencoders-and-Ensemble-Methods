{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from prettytable import PrettyTable\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pre Requisite ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression for Classification ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionScratch():\n",
    "    def __init__(self, learning_rate, threshold = 0.5, epochs = 700):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.threshold = threshold\n",
    "        self.loss = 0\n",
    "        self.epochs = epochs\n",
    "        return\n",
    "    \n",
    "\n",
    "    def softmax(self, x):\n",
    "        exponent = np.dot(x, self.weights) + self.bias\n",
    "        exponent = np.exp(exponent)\n",
    "        exponent /= np.sum(exponent, axis=1, keepdims=True)\n",
    "        return exponent\n",
    "\n",
    "\n",
    "    def cross_entropy_loss(self, x_train, y_train):           # Vectorised code generated from ChatGPT \n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(self.y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -np.sum(np.multiply(y_train, np.log(y_pred)))\n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def gradient(self, x_train, y_train):                     # Vectorised code generated from ChatGPT \n",
    "        weight_gradient = np.dot(x_train.T, (self.y_pred - y_train)) / x_train.shape[0]\n",
    "        bias_gradient = np.mean(self.y_pred - y_train, axis=0)\n",
    "        return weight_gradient, bias_gradient\n",
    "    \n",
    "\n",
    "    def forward(self, x_train, y_train):\n",
    "        self.y_pred = self.softmax(x_train)\n",
    "        loss = self.cross_entropy_loss(x_train, y_train)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def backward(self, x_train, y_train):\n",
    "        weight_gradient, bias_gradient = self.gradient(x_train, y_train)\n",
    "        self.weights -= self.learning_rate * weight_gradient\n",
    "        self.bias -= self.learning_rate * bias_gradient\n",
    "        return\n",
    "\n",
    "\n",
    "    def one_hot_encoding(self, Y):              # generated from ChatGPT\n",
    "        OneHotEncoding = []\n",
    "        encoding = []\n",
    "        \n",
    "        for i in range(len(Y)):\n",
    "            encoding = np.zeros(self.k)\n",
    "            encoding[self.labels_dict[Y[i]]] = 1\n",
    "            OneHotEncoding.append(encoding)\n",
    "        return OneHotEncoding\n",
    "\n",
    "\n",
    "    def max_class(self, y_pred):\n",
    "        return np.argmax(y_pred)\n",
    "    \n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        labels, counts = np.unique(y_train, return_counts=True)\n",
    "        self.k = counts.shape[0]\n",
    "        self.labels_dict = {}\n",
    "        for i in range(len(labels)):\n",
    "            self.labels_dict[int(labels[i])] = i\n",
    "\n",
    "\n",
    "        weights = np.zeros((x_train.shape[1], self.k))\n",
    "        bias = np.zeros(self.k)\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "        y_one_hot = self.one_hot_encoding(y_train)\n",
    "\n",
    "        \n",
    "        epoch = 0\n",
    "        self.y_pred = self.softmax(x_train)\n",
    "        while abs(self.loss-self.cross_entropy_loss(x_train, y_one_hot)) > 1e-8 and epoch < self.epochs:\n",
    "            self.loss = self.forward(x_train, y_one_hot)\n",
    "            self.backward(x_train, y_one_hot)\n",
    "            accuracy = self.evaluation(self.y_pred, y_one_hot)\n",
    "            # print(\"Epoch = \",epoch+1, \"Loss = \", self.loss, \"Accuracy = \", accuracy)\n",
    "            epoch += 1\n",
    "        return\n",
    "    \n",
    "\n",
    "    def predict(self, x_test, y_test):\n",
    "        # y_one_hot = self.one_hot_encoding(y_test)\n",
    "        # self.loss = self.forward(x_test, y_one_hot)\n",
    "        # self.backward(x_test, y_one_hot)\n",
    "        self.y_pred = self.softmax(x_test)\n",
    "        return np.argmax(self.y_pred, axis=1)+3\n",
    "\n",
    "\n",
    "    def evaluation(self, predicted, actual):\n",
    "        score = 0\n",
    "        for i in range(predicted.shape[0]):\n",
    "            if (self.max_class(actual[i]) == self.max_class(predicted[i])):\n",
    "                score += 1\n",
    "        return score/predicted.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression for Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, learning_rate, epochs):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        return\n",
    "\n",
    "\n",
    "    def loss(self, x_train, y_train):\n",
    "        y_pred = np.dot(x_train, self.weights[:, np.newaxis])\n",
    "        temp = np.array([])\n",
    "        for i in range(y_pred.shape[0]):\n",
    "            temp = np.append(temp, np.array([y_pred[i]]))\n",
    "        mse = np.sum(np.square(temp-y_train)) / (2 * x_train.shape[0])\n",
    "        y_mean = np.mean(temp)\n",
    "        SS_res = mse * x_train.shape[0]\n",
    "        SS_tot = np.sum(np.square(y_train-y_mean))\n",
    "        r_squared = 1 - SS_res / SS_tot\n",
    "        return mse, r_squared\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x_train, y_train):\n",
    "        mse, r_squared = self.loss(x_train, y_train)\n",
    "        return mse, r_squared\n",
    "    \n",
    "\n",
    "\n",
    "    def gradient(self, x_train, y_train):\n",
    "        predictions = np.dot(x_train, self.weights)\n",
    "        errors = predictions - y_train\n",
    "        grad = np.dot(errors, x_train) / x_train.shape[0]\n",
    "        return grad\n",
    "\n",
    "\n",
    "    def backward(self, x_train, y_train):\n",
    "        gradient = self.gradient(x_train, y_train)\n",
    "        self.weights -= self.learning_rate * gradient\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return np.dot(x_test, self.weights)\n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        weights = np.random.randn(x_train.shape[1])\n",
    "        self.weights = weights\n",
    "        for epoch in range(self.epochs):\n",
    "            mse, r_sq = self.forward(x_train, y_train)\n",
    "            self.backward(x_train, y_train)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptrons for Classification ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassification():\n",
    "    def __init__(self, learning_rate, activation = 'Sigmoid', optimiser = 'BGD', num_hidden = 5, num_neurons = 11, epochs = 400):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "        self.optimiser = optimiser\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_neurons = num_neurons\n",
    "        self.loss = 0\n",
    "        self.epochs = epochs\n",
    "        return\n",
    "\n",
    "\n",
    "    def cross_entropy_loss(self, layer_input, layer_output):\n",
    "        epsilon = 1e-15\n",
    "        y_pred = np.clip(self.y_pred, epsilon, 1 - epsilon)\n",
    "        loss = -np.sum(np.multiply(layer_output, np.log(y_pred))) / layer_input.shape[0]\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def activate(self, layer_input):\n",
    "        if (self.activation == 'Sigmoid'):\n",
    "            return 1 / (1+np.exp(-layer_input))\n",
    "        elif (self.activation == 'Tanh'):\n",
    "            return (1-np.exp(-2*layer_input)) / (1+np.exp(-2*layer_input))\n",
    "        elif (self.activation == 'ReLU'):\n",
    "            return np.maximum(0, layer_input)\n",
    "        return\n",
    "\n",
    "\n",
    "    def diff_activate(self, input):\n",
    "        if (self.activation == 'Sigmoid'):\n",
    "            sig_val = self.activate(input)\n",
    "            return sig_val * (1-sig_val)\n",
    "        \n",
    "        elif (self.activation == 'Tanh'):\n",
    "            tanh_val = self.activate(input)\n",
    "            return 1-tanh_val*tanh_val\n",
    "        \n",
    "        elif (self.activation == 'ReLU'):\n",
    "            return np.where(input <= 0, 0, 1)               # taken from ChatGPT\n",
    "        return\n",
    "\n",
    "\n",
    "    # def diff_softmax(self, z):\n",
    "    #     e_z = np.exp(z)\n",
    "    #     softmax = e_z / np.sum(e_z)\n",
    "    #     derivative = softmax * (1 - softmax)\n",
    "    #     return derivative\n",
    "\n",
    "\n",
    "    # def softmax(self, x):\n",
    "    #     exponent = np.exp(x)\n",
    "    #     exponent /= np.sum(exponent, axis=0, keepdims=True)\n",
    "    #     return exponent\n",
    "\n",
    "\n",
    "\n",
    "    def diff_softmax(self, z):\n",
    "        e_z = np.exp(z - np.max(z))\n",
    "        softmax = e_z / np.sum(e_z)\n",
    "        derivative = softmax * (1 - softmax)\n",
    "        return derivative\n",
    "\n",
    "\n",
    "    def softmax(self, x):\n",
    "        x_max = np.max(x, axis=0, keepdims=True)\n",
    "        exponent = np.exp(x - x_max)\n",
    "        softmax = exponent / np.sum(exponent, axis=0, keepdims=True)\n",
    "        return softmax\n",
    "\n",
    "    \n",
    "    \n",
    "    def one_hot_encoding(self, Y):              # generated from ChatGPT\n",
    "        OneHotEncoding = np.zeros((Y.shape[0], self.k))\n",
    "        \n",
    "        for i in range(len(Y)):\n",
    "            encoding = np.zeros(self.k)\n",
    "            encoding[self.labels_dict[Y[i]]] = 1\n",
    "            OneHotEncoding[i] = encoding\n",
    "        return OneHotEncoding\n",
    "    \n",
    "\n",
    "\n",
    "    def gradient(self, layer_input, layer_output):\n",
    "        \n",
    "        \n",
    "        if (self.optimiser == 'SGD'):\n",
    "            \n",
    "            indices = np.arange(layer_input.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "            self.loss = 0\n",
    "\n",
    "            for j in range(layer_input.shape[0]):\n",
    "                \n",
    "                self.loss += self.forward_prop(layer_input[j], layer_output[j])\n",
    "                delta = -(layer_output[j]-self.y_pred)\n",
    "                dJdw = np.dot(self.a[len(self.a)-1][:, np.newaxis], np.transpose(delta[:, np.newaxis]))\n",
    "                self.weights[len(self.z)-1] -= self.learning_rate*dJdw\n",
    "                bias_grad = np.mean(delta, axis = 0)\n",
    "                self.bias[len(self.z) - 1] -= self.learning_rate * bias_grad\n",
    "\n",
    "                for i in range(self.num_hidden):\n",
    "                    delta = np.multiply(self.diff_activate(self.z[len(self.z)-2-i]), np.dot(delta, np.transpose(self.weights[len(self.z)-1-i])))                    \n",
    "                    if (i == self.num_hidden-1):\n",
    "                        dJdw = np.dot(layer_input[j][:, np.newaxis], np.transpose(delta[:, np.newaxis]))\n",
    "                    else:\n",
    "                        dJdw = np.dot(self.a[len(self.a)-2-i][:, np.newaxis], np.transpose(delta[:, np.newaxis]))\n",
    "                    self.weights[len(self.z)-2-i] -= self.learning_rate*dJdw\n",
    "                    bias_grad = np.mean(delta, axis = 0)\n",
    "                    self.bias[len(self.z)-2-i] -= self.learning_rate * bias_grad\n",
    "\n",
    "            return\n",
    "\n",
    "\n",
    "\n",
    "        if (self.optimiser == 'BGD'):\n",
    "\n",
    "            self.loss = self.forward_prop(layer_input, layer_output)\n",
    "            delta = -(layer_output - self.y_pred)\n",
    "            dJdw = np.dot(np.transpose(self.a[len(self.a)-1]), delta)\n",
    "            self.weights[len(self.z)-1] -= self.learning_rate*dJdw\n",
    "            bias_grad = np.mean(delta, axis = 0)\n",
    "            self.bias[len(self.z) - 1] -= self.learning_rate * bias_grad\n",
    "\n",
    "            for i in range(self.num_hidden):\n",
    "                delta = np.multiply(self.diff_activate(self.z[len(self.z)-2-i]), np.dot(delta, np.transpose(self.weights[len(self.z)-1-i])))\n",
    "                if (i == self.num_hidden-1):\n",
    "                    dJdw = np.dot(np.transpose(layer_input), delta)\n",
    "                else:\n",
    "                    dJdw = np.dot(np.transpose(self.a[len(self.a)-2-i]), delta)\n",
    "                self.weights[len(self.z)-2-i] -= self.learning_rate*dJdw\n",
    "                bias_grad = np.mean(delta, axis = 0)\n",
    "                self.bias[len(self.z)-2-i] -= self.learning_rate * bias_grad\n",
    "\n",
    "\n",
    "        if (self.optimiser == 'Mini-BGD'):\n",
    "\n",
    "            batch_size = 50\n",
    "            self.loss = 0\n",
    "\n",
    "            for j in range(int(layer_input.shape[0]/batch_size)):\n",
    "\n",
    "                self.loss += self.forward_prop(layer_input[batch_size*j: batch_size*(j+1), ], layer_output[batch_size*j: batch_size*(j+1), ])\n",
    "                delta = -(layer_output[batch_size*j: batch_size*(j+1), ] - self.y_pred)\n",
    "                dJdw = np.dot(np.transpose(self.a[len(self.a)-1]), delta)\n",
    "                self.weights[len(self.z)-1] -= self.learning_rate*dJdw\n",
    "                bias_grad = np.mean(delta, axis = 0)\n",
    "                self.bias[len(self.z) - 1] -= self.learning_rate * bias_grad\n",
    "\n",
    "\n",
    "                for i in range(self.num_hidden):\n",
    "                    delta = np.multiply(self.diff_activate(self.z[len(self.z)-2-i]), np.dot(delta, np.transpose(self.weights[len(self.z)-1-i]))) \n",
    "                    if (i == self.num_hidden-1):\n",
    "                        dJdw = np.dot(np.transpose(layer_input[batch_size*j: batch_size*(j+1), ]), delta)\n",
    "                    else:\n",
    "                        dJdw = np.dot(np.transpose(self.a[len(self.a)-2-i]), delta)\n",
    "                    self.weights[len(self.z)-2-i] -= self.learning_rate*dJdw\n",
    "                    bias_grad = np.mean(delta, axis = 0)\n",
    "                    self.bias[len(self.z)-2-i] -= self.learning_rate * bias_grad\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def back_prop(self, layer_input, layer_output):\n",
    "        self.gradient(layer_input, layer_output)\n",
    "        return\n",
    "    \n",
    "\n",
    "    def forward_prop(self, layer_input, layer_output):\n",
    "        self.z = []\n",
    "        self.a = []\n",
    "        for i in range(self.num_hidden+1):\n",
    "            z = np.dot(layer_input, self.weights[i])\n",
    "            if (self.optimiser == 'SGD'):\n",
    "                z += self.bias[i]\n",
    "            else:\n",
    "                for j in range(z.shape[0]):\n",
    "                    z[j] += self.bias[i]\n",
    "            \n",
    "            a = None\n",
    "            if (i == self.num_hidden):\n",
    "                a = self.softmax(z)\n",
    "            else:\n",
    "                a = self.activate(z)\n",
    "            \n",
    "            self.z.append(z)\n",
    "            if (i != self.num_hidden):\n",
    "                self.a.append(a)\n",
    "            layer_input = a\n",
    "\n",
    "        self.y_pred = layer_input\n",
    "        loss = self.cross_entropy_loss(layer_output, self.y_pred)\n",
    "        return abs(loss)\n",
    "\n",
    "\n",
    "    def initialize_weights_and_biases(self, layer_sizes):\n",
    "        weights = []\n",
    "        bias = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            input_units = layer_sizes[i - 1]\n",
    "            output_units = layer_sizes[i]\n",
    "            weight_matrix = np.random.randn(input_units, output_units) * np.sqrt(2 / input_units)\n",
    "            bias_vector = np.random.randn(output_units)\n",
    "            weights.append(weight_matrix)\n",
    "            bias.append(bias_vector)\n",
    "        return weights, bias\n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.labels_dict = {}\n",
    "        self.k = 6\n",
    "        for i in range(3, 9):\n",
    "            self.labels_dict[i] = i-3\n",
    "\n",
    "        y_one_hot = self.one_hot_encoding(y_train)\n",
    "        layer_sizes = [x_train.shape[1]]\n",
    "        for _ in range(self.num_hidden):\n",
    "            layer_sizes.append(self.num_neurons)\n",
    "        layer_sizes.append(y_one_hot.shape[1])\n",
    "        self.weights, self.bias = self.initialize_weights_and_biases(layer_sizes)\n",
    "        \n",
    "        epoch = 0\n",
    "        self.y_pred = self.softmax(y_one_hot)\n",
    "        while abs(self.loss-self.cross_entropy_loss(x_train, y_one_hot)) > 1e-8 and epoch < self.epochs:\n",
    "            self.back_prop(x_train, y_one_hot)\n",
    "            epoch += 1\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, x_test, y_test):\n",
    "        y_one_hot = self.one_hot_encoding(y_test)\n",
    "        self.forward_prop(x_test, y_one_hot)\n",
    "        return np.argmax(self.y_pred)\n",
    "\n",
    "\n",
    "    def max_class(self, y_pred):\n",
    "        return np.argmax(y_pred)\n",
    "\n",
    "\n",
    "    def evaluation(self, predicted, actual):\n",
    "        l1 = np.array([])\n",
    "        l2 = np.array([])\n",
    "        for i in range(predicted.shape[0]):\n",
    "            l1 = np.append(l1, np.array([self.max_class(actual[i])]))\n",
    "            l2 = np.append(l2, np.array([self.max_class(predicted[i])]))\n",
    "        return accuracy_score(l1, l2), precision_score(l1, l2, average = \"weighted\", zero_division=True), recall_score(l1, l2, average = \"weighted\", zero_division=True), f1_score(l1, l2, average = \"weighted\", zero_division=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptrons for Regression ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegression():\n",
    "    def __init__(self, learning_rate, activation = 'Sigmoid', optimiser = 'BGD', num_hidden = 5, num_neurons = 11, epochs = 700):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.activation = activation\n",
    "        self.optimiser = optimiser\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_neurons = num_neurons\n",
    "        self.loss = 0\n",
    "        self.epochs = epochs\n",
    "        return\n",
    "\n",
    "\n",
    "    def predict(self, x_test, y_test):\n",
    "        self.forward_prop(x_test, y_test)\n",
    "        return np.squeeze(self.y_pred)\n",
    "\n",
    "\n",
    "    def activate(self, layer_input):\n",
    "        if (self.activation == 'Sigmoid'):\n",
    "            return 1 / (1+np.exp(-layer_input))\n",
    "        elif (self.activation == 'Tanh'):\n",
    "            return (1-np.exp(-2*layer_input)) / (1+np.exp(-2*layer_input))\n",
    "        elif (self.activation == 'ReLU'):\n",
    "            return np.maximum(0, layer_input)\n",
    "        return\n",
    "\n",
    "\n",
    "    def diff_activate(self, input):\n",
    "        if (self.activation == 'Sigmoid'):\n",
    "            sig_val = self.activate(input)\n",
    "            return sig_val * (1-sig_val)\n",
    "        elif (self.activation == 'Tanh'):\n",
    "            tanh_val = self.activate(input)\n",
    "            return 1-tanh_val*tanh_val\n",
    "        elif (self.activation == 'ReLU'):\n",
    "            return np.where(input <= 0, 0, 1)               # taken from ChatGPT\n",
    "        return\n",
    "\n",
    "\n",
    "\n",
    "    def gradient(self, layer_input, layer_output):\n",
    "        \n",
    "        \n",
    "        if (self.optimiser == 'SGD'):\n",
    "\n",
    "            indices = np.arange(layer_input.shape[0])\n",
    "            np.random.shuffle(indices)\n",
    "    \n",
    "\n",
    "            for j in range(layer_input.shape[0]):\n",
    "                \n",
    "                self.loss = self.forward_prop(layer_input[j], layer_output[j])\n",
    "                y = layer_output[j].reshape(1, 1)\n",
    "                delta = -(y-self.y_pred)\n",
    "                dJdw = np.dot(self.a[len(self.a)-1][:, np.newaxis], delta)\n",
    "                self.weights[len(self.z)-1] -= self.learning_rate*dJdw\n",
    "                bias_grad = np.mean(delta, axis = 0)\n",
    "                self.bias[len(self.z) - 1] -= self.learning_rate * bias_grad\n",
    "\n",
    "                for i in range(self.num_hidden):\n",
    "                    delta = np.multiply(self.diff_activate(self.z[len(self.z)-2-i]), np.dot(delta, np.transpose(self.weights[len(self.z)-1-i])))                    \n",
    "                    if (i == self.num_hidden-1):\n",
    "                        dJdw = np.dot(layer_input[j][:, np.newaxis], delta)\n",
    "                    else:\n",
    "                        dJdw = np.dot(self.a[len(self.a)-2-i][:, np.newaxis], delta)\n",
    "                    self.weights[len(self.z)-2-i] -= self.learning_rate*dJdw\n",
    "                    bias_grad = np.mean(delta, axis = 0)\n",
    "                    self.bias[len(self.z)-2-i] -= self.learning_rate * bias_grad\n",
    "\n",
    "            return\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        if (self.optimiser == 'BGD'):\n",
    "            \n",
    "            self.loss = self.forward_prop(layer_input, layer_output)\n",
    "            y = layer_output.reshape(len(layer_output), 1)\n",
    "            delta = -(y-self.y_pred)\n",
    "            dJdw = np.dot(np.transpose(self.a[len(self.a)-1]), delta) / layer_input.shape[0]\n",
    "            self.weights[len(self.z)-1] -= self.learning_rate*dJdw\n",
    "            # bias_grad1 = np.transpose(delta[0])\n",
    "            # bias_grad = np.asarray(bias_grad1).reshape(-1)\n",
    "            bias_grad = np.mean(delta, axis = 0)\n",
    "            self.bias[len(self.z) - 1] -= self.learning_rate * bias_grad\n",
    "\n",
    "            for i in range(self.num_hidden):\n",
    "                delta = np.multiply(self.diff_activate(self.z[len(self.z)-2-i]), np.dot(delta, np.transpose(self.weights[len(self.z)-1-i])))\n",
    "                if (i == self.num_hidden-1):\n",
    "                    dJdw = np.dot(np.transpose(layer_input), delta) / layer_input.shape[0]                 \n",
    "                else:\n",
    "                    dJdw = np.dot(np.transpose(self.a[len(self.a)-2-i]), delta) / layer_input.shape[0]\n",
    "                self.weights[len(self.z)-2-i] -= self.learning_rate*dJdw\n",
    "                bias_grad = np.mean(delta, axis = 0)\n",
    "                self.bias[len(self.z)-2-i] -= self.learning_rate * bias_grad\n",
    "            return\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        if (self.optimiser == 'Mini-BGD'):\n",
    "\n",
    "            batch_size = int(layer_input.shape[0]/6)\n",
    "            for j in range(int(layer_input.shape[0]/batch_size)):\n",
    "\n",
    "                self.loss = self.forward_prop(layer_input[batch_size*j: batch_size*(j+1), ], layer_output[batch_size*j: batch_size*(j+1), ])\n",
    "                y = layer_output.reshape(len(layer_output), 1)\n",
    "                delta = -(y[batch_size*j: batch_size*(j+1), ]-self.y_pred)\n",
    "                dJdw = np.dot(np.transpose(self.a[len(self.a)-1]), delta) / batch_size\n",
    "                self.weights[len(self.z)-1] -= self.learning_rate*dJdw\n",
    "                bias_grad = np.mean(delta, axis = 0)\n",
    "                self.bias[len(self.z) - 1] -= self.learning_rate * bias_grad\n",
    "\n",
    "\n",
    "                for i in range(self.num_hidden):\n",
    "                    delta = np.multiply(self.diff_activate(self.z[len(self.z)-2-i]), np.dot(delta, np.transpose(self.weights[len(self.z)-1-i])))\n",
    "                    if (i == self.num_hidden-1):\n",
    "                        dJdw = np.dot(np.transpose(layer_input[batch_size*j: batch_size*(j+1), ]), delta) / batch_size\n",
    "                    else:\n",
    "                        dJdw = np.dot(np.transpose(self.a[len(self.a)-2-i]), delta) / batch_size\n",
    "                    self.weights[len(self.z)-2-i] -= self.learning_rate*dJdw\n",
    "                    bias_grad = np.mean(delta, axis = 0)\n",
    "                    self.bias[len(self.z)-2-i] -= self.learning_rate * bias_grad\n",
    "\n",
    "            return\n",
    "        \n",
    "\n",
    "\n",
    "    def back_prop(self, layer_input, layer_output):\n",
    "        self.gradient(layer_input, layer_output)\n",
    "        return\n",
    "    \n",
    "\n",
    "    def forward_prop(self, layer_input, layer_output):\n",
    "        self.z = []\n",
    "        self.a = []\n",
    "        for i in range(self.num_hidden+1):\n",
    "            z = np.dot(layer_input, self.weights[i])\n",
    "\n",
    "            if (self.optimiser == 'SGD'):\n",
    "                z += self.bias[i]\n",
    "            else:\n",
    "                for j in range(z.shape[0]):\n",
    "                    z[j] += self.bias[i]\n",
    "            \n",
    "            a = self.activate(z)\n",
    "            self.z.append(z)\n",
    "            if (i != self.num_hidden):\n",
    "                self.a.append(a)\n",
    "            layer_input = a\n",
    "        self.y_pred = layer_input\n",
    "        loss = np.mean(np.square(layer_output-self.y_pred))\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def loss_compute(self, layer_output):\n",
    "        y_mean = np.mean(layer_output)\n",
    "        y_pred = self.y_pred.reshape(layer_output.shape[0])\n",
    "        numerator = np.sum(np.square(layer_output - y_pred))\n",
    "        denominator = np.sum(np.square(layer_output - y_mean))\n",
    "        r_squared = 1 - (numerator / denominator)\n",
    "        return r_squared\n",
    "\n",
    "\n",
    "\n",
    "    def initialize_weights_and_biases(self, layer_sizes):\n",
    "        weights = []\n",
    "        bias = []\n",
    "        for i in range(1, len(layer_sizes)):\n",
    "            input_units = layer_sizes[i - 1]\n",
    "            output_units = layer_sizes[i]\n",
    "            weight_matrix = np.random.randn(input_units, output_units) * np.sqrt(2 / input_units)\n",
    "            bias_vector = np.random.randn(output_units)\n",
    "            weights.append(weight_matrix)\n",
    "            bias.append(bias_vector)\n",
    "        return weights, bias\n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        layer_sizes = [x_train.shape[1]]\n",
    "        for _ in range(self.num_hidden):\n",
    "            layer_sizes.append(self.num_neurons)\n",
    "        layer_sizes.append(1)\n",
    "        self.weights, self.bias = self.initialize_weights_and_biases(layer_sizes)\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            self.back_prop(x_train, y_train)\n",
    "            # r_sq = self.loss_compute(y_train)\n",
    "            # print(\"Epoch = \", epoch+1, \"MSE = \", self.loss, \"RMSE = \", np.sqrt(self.loss), \"R-Squared Error = \", r_sq)\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.068</td>\n",
       "      <td>28.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.99651</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.82</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1138            6.3             0.510         0.13             2.3      0.076   \n",
       "1139            6.8             0.620         0.08             1.9      0.068   \n",
       "1140            6.2             0.600         0.08             2.0      0.090   \n",
       "1141            5.9             0.550         0.10             2.2      0.062   \n",
       "1142            5.9             0.645         0.12             2.0      0.075   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1138                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1139                 28.0                  38.0  0.99651  3.42       0.82   \n",
       "1140                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1141                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1142                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1138     11.0        6  \n",
       "1139      9.5        6  \n",
       "1140     10.5        5  \n",
       "1141     11.2        6  \n",
       "1142     10.2        5  \n",
       "\n",
       "[1143 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classification = pd.read_csv('./WineQT.csv')\n",
    "data_classification = data_classification.drop(columns=['Id'])\n",
    "l = [i for i in data_classification]\n",
    "data_classification = data_classification.dropna()\n",
    "data_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Attribute</th>\n",
       "            <th>Mean</th>\n",
       "            <th>Standard Deviation</th>\n",
       "            <th>Minimum Value</th>\n",
       "            <th>Maximum</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>fixed acidity</td>\n",
       "            <td>8.311111111111119</td>\n",
       "            <td>1.7468303726275005</td>\n",
       "            <td>4.6</td>\n",
       "            <td>15.9</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>volatile acidity</td>\n",
       "            <td>0.531338582677165</td>\n",
       "            <td>0.17955459612835611</td>\n",
       "            <td>0.12</td>\n",
       "            <td>1.58</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>citric acid</td>\n",
       "            <td>0.26836395450568584</td>\n",
       "            <td>0.19659979421574753</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>residual sugar</td>\n",
       "            <td>2.5321522309711257</td>\n",
       "            <td>1.3553241971435854</td>\n",
       "            <td>0.9</td>\n",
       "            <td>15.5</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>chlorides</td>\n",
       "            <td>0.08693263342082211</td>\n",
       "            <td>0.04724665655215519</td>\n",
       "            <td>0.012</td>\n",
       "            <td>0.611</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>free sulfur dioxide</td>\n",
       "            <td>15.615485564304462</td>\n",
       "            <td>10.246001115067603</td>\n",
       "            <td>1.0</td>\n",
       "            <td>68.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>total sulfur dioxide</td>\n",
       "            <td>45.91469816272966</td>\n",
       "            <td>32.767786779941396</td>\n",
       "            <td>6.0</td>\n",
       "            <td>289.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>density</td>\n",
       "            <td>0.9967304111986008</td>\n",
       "            <td>0.0019242248343795283</td>\n",
       "            <td>0.99007</td>\n",
       "            <td>1.00369</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>pH</td>\n",
       "            <td>3.3110148731408593</td>\n",
       "            <td>0.15659551281704343</td>\n",
       "            <td>2.74</td>\n",
       "            <td>4.01</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>sulphates</td>\n",
       "            <td>0.6577077865266842</td>\n",
       "            <td>0.17032415803626072</td>\n",
       "            <td>0.33</td>\n",
       "            <td>2.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>alcohol</td>\n",
       "            <td>10.44211140274131</td>\n",
       "            <td>1.0817221048833665</td>\n",
       "            <td>8.4</td>\n",
       "            <td>14.9</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+----------------------+---------------------+-----------------------+---------------+---------+\n",
       "|      Attribute       |         Mean        |   Standard Deviation  | Minimum Value | Maximum |\n",
       "+----------------------+---------------------+-----------------------+---------------+---------+\n",
       "|    fixed acidity     |  8.311111111111119  |   1.7468303726275005  |      4.6      |   15.9  |\n",
       "|   volatile acidity   |  0.531338582677165  |  0.17955459612835611  |      0.12     |   1.58  |\n",
       "|     citric acid      | 0.26836395450568584 |  0.19659979421574753  |      0.0      |   1.0   |\n",
       "|    residual sugar    |  2.5321522309711257 |   1.3553241971435854  |      0.9      |   15.5  |\n",
       "|      chlorides       | 0.08693263342082211 |  0.04724665655215519  |     0.012     |  0.611  |\n",
       "| free sulfur dioxide  |  15.615485564304462 |   10.246001115067603  |      1.0      |   68.0  |\n",
       "| total sulfur dioxide |  45.91469816272966  |   32.767786779941396  |      6.0      |  289.0  |\n",
       "|       density        |  0.9967304111986008 | 0.0019242248343795283 |    0.99007    | 1.00369 |\n",
       "|          pH          |  3.3110148731408593 |  0.15659551281704343  |      2.74     |   4.01  |\n",
       "|      sulphates       |  0.6577077865266842 |  0.17032415803626072  |      0.33     |   2.0   |\n",
       "|       alcohol        |  10.44211140274131  |   1.0817221048833665  |      8.4      |   14.9  |\n",
       "+----------------------+---------------------+-----------------------+---------------+---------+"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classification = np.array([data_classification])\n",
    "data_classification = data_classification[0]\n",
    "mean = np.mean(data_classification, axis = 0)\n",
    "std = np.std(data_classification, axis = 0)\n",
    "minimum = np.min(data_classification, axis = 0)\n",
    "maximum = np.max(data_classification, axis = 0)\n",
    "table = PrettyTable(['Attribute', 'Mean', 'Standard Deviation', 'Minimum Value', 'Maximum'])\n",
    "for i in range(data_classification.shape[1]-1):\n",
    "    table.add_row([l[i], mean[i], std[i], minimum[i], maximum[i]])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((data_classification.shape[0], data_classification.shape[1]-1))\n",
    "for i in range(data_classification.shape[1]-1):\n",
    "    X[:, i] = data_classification[:, i]\n",
    "y = data_classification[:, data_classification.shape[1]-1]\n",
    "x_train_c, x_test_c, y_train_c, y_test_c = train_test_split(X, y, test_size=0.3)\n",
    "x_test_c, x_val_c, y_test_c, y_val_c = train_test_split(x_test_c, y_test_c, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.200000</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.980000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.900000</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.140000</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.100000</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.030000</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.800000</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.940000</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.200000</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.100000</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>12.715432</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.700000</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.640000</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.300000</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.480000</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>68.518519</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.880000</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM        AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.200000  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.900000  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.100000  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.800000  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.200000  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...        ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.100000  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.700000  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.000000  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.300000  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  68.518519  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B      LSTAT  MEDV  \n",
       "0       15.3  396.90   4.980000  24.0  \n",
       "1       17.8  396.90   9.140000  21.6  \n",
       "2       17.8  392.83   4.030000  34.7  \n",
       "3       18.7  394.63   2.940000  33.4  \n",
       "4       18.7  396.90  12.715432  36.2  \n",
       "..       ...     ...        ...   ...  \n",
       "501     21.0  391.99  12.715432  22.4  \n",
       "502     21.0  396.90   9.080000  20.6  \n",
       "503     21.0  396.90   5.640000  23.9  \n",
       "504     21.0  393.45   6.480000  22.0  \n",
       "505     21.0  396.90   7.880000  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regression = pd.read_csv('./HousingData.csv')\n",
    "l = [i for i in data_regression]\n",
    "mean_result = data_regression.mean(skipna=True)\n",
    "std_result = data_regression.std(skipna=True)\n",
    "\n",
    "data_types = data_regression.dtypes\n",
    "for i in range(len(l)):\n",
    "    if (data_types[i] == 'object' or data_types[i] == 'bool'):\n",
    "        continue\n",
    "    data_regression = data_regression.fillna({l[i]: mean_result[l[i]]})\n",
    "data_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Attribute</th>\n",
       "            <th>Mean</th>\n",
       "            <th>Standard Deviation</th>\n",
       "            <th>Minimum Value</th>\n",
       "            <th>Maximum</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>CRIM</td>\n",
       "            <td>3.611873971193416</td>\n",
       "            <td>8.537321779593817</td>\n",
       "            <td>0.00632</td>\n",
       "            <td>88.9762</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>ZN</td>\n",
       "            <td>11.211934156378598</td>\n",
       "            <td>22.898390901831366</td>\n",
       "            <td>0.0</td>\n",
       "            <td>100.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>INDUS</td>\n",
       "            <td>11.08399176954735</td>\n",
       "            <td>6.6925417540998104</td>\n",
       "            <td>0.46</td>\n",
       "            <td>27.74</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>CHAS</td>\n",
       "            <td>0.06995884773662546</td>\n",
       "            <td>0.24998576709269318</td>\n",
       "            <td>0.0</td>\n",
       "            <td>1.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>NOX</td>\n",
       "            <td>0.5546950592885372</td>\n",
       "            <td>0.11576311540656153</td>\n",
       "            <td>0.385</td>\n",
       "            <td>0.871</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>RM</td>\n",
       "            <td>6.284634387351787</td>\n",
       "            <td>0.7019225143345692</td>\n",
       "            <td>3.561</td>\n",
       "            <td>8.78</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>AGE</td>\n",
       "            <td>68.51851851851853</td>\n",
       "            <td>27.412338662278373</td>\n",
       "            <td>2.9</td>\n",
       "            <td>100.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>DIS</td>\n",
       "            <td>3.795042687747034</td>\n",
       "            <td>2.103628356344459</td>\n",
       "            <td>1.1296</td>\n",
       "            <td>12.1265</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>RAD</td>\n",
       "            <td>9.549407114624506</td>\n",
       "            <td>8.698651117790645</td>\n",
       "            <td>1.0</td>\n",
       "            <td>24.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>TAX</td>\n",
       "            <td>408.2371541501976</td>\n",
       "            <td>168.3704950393814</td>\n",
       "            <td>187.0</td>\n",
       "            <td>711.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>PTRATIO</td>\n",
       "            <td>18.455533596837967</td>\n",
       "            <td>2.162805191482142</td>\n",
       "            <td>12.6</td>\n",
       "            <td>22.0</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>B</td>\n",
       "            <td>356.67403162055257</td>\n",
       "            <td>91.20460745217272</td>\n",
       "            <td>0.32</td>\n",
       "            <td>396.9</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>LSTAT</td>\n",
       "            <td>12.71543209876544</td>\n",
       "            <td>7.0058059292206805</td>\n",
       "            <td>1.73</td>\n",
       "            <td>37.97</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-----------+---------------------+---------------------+---------------+---------+\n",
       "| Attribute |         Mean        |  Standard Deviation | Minimum Value | Maximum |\n",
       "+-----------+---------------------+---------------------+---------------+---------+\n",
       "|    CRIM   |  3.611873971193416  |  8.537321779593817  |    0.00632    | 88.9762 |\n",
       "|     ZN    |  11.211934156378598 |  22.898390901831366 |      0.0      |  100.0  |\n",
       "|   INDUS   |  11.08399176954735  |  6.6925417540998104 |      0.46     |  27.74  |\n",
       "|    CHAS   | 0.06995884773662546 | 0.24998576709269318 |      0.0      |   1.0   |\n",
       "|    NOX    |  0.5546950592885372 | 0.11576311540656153 |     0.385     |  0.871  |\n",
       "|     RM    |  6.284634387351787  |  0.7019225143345692 |     3.561     |   8.78  |\n",
       "|    AGE    |  68.51851851851853  |  27.412338662278373 |      2.9      |  100.0  |\n",
       "|    DIS    |  3.795042687747034  |  2.103628356344459  |     1.1296    | 12.1265 |\n",
       "|    RAD    |  9.549407114624506  |  8.698651117790645  |      1.0      |   24.0  |\n",
       "|    TAX    |  408.2371541501976  |  168.3704950393814  |     187.0     |  711.0  |\n",
       "|  PTRATIO  |  18.455533596837967 |  2.162805191482142  |      12.6     |   22.0  |\n",
       "|     B     |  356.67403162055257 |  91.20460745217272  |      0.32     |  396.9  |\n",
       "|   LSTAT   |  12.71543209876544  |  7.0058059292206805 |      1.73     |  37.97  |\n",
       "+-----------+---------------------+---------------------+---------------+---------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regression = np.array([data_regression])\n",
    "data_regression = data_regression[0]\n",
    "mean = np.mean(data_regression, axis = 0)\n",
    "std = np.std(data_regression, axis = 0)\n",
    "minimum = np.min(data_regression, axis = 0)\n",
    "maximum = np.max(data_regression, axis = 0)\n",
    "table = PrettyTable(['Attribute', 'Mean', 'Standard Deviation', 'Minimum Value', 'Maximum'])\n",
    "for i in range(data_regression.shape[1]-1):\n",
    "    table.add_row([l[i], mean[i], std[i], minimum[i], maximum[i]])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regression = np.array([data_regression])\n",
    "data_regression = data_regression[0]\n",
    "\n",
    "mean = np.mean(data_regression, axis = 0)\n",
    "std = np.std(data_regression, axis = 0)\n",
    "data_regression -= mean\n",
    "data_regression /= std\n",
    "\n",
    "X = np.zeros((data_regression.shape[0], data_regression.shape[1]-1))\n",
    "for i in range(data_regression.shape[1]-1):\n",
    "    X[:, i] = data_regression[:, i]\n",
    "y = data_regression[:, data_regression.shape[1]-1]\n",
    "\n",
    "x_train_r, x_test_r, y_train_r, y_test_r = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "x_test_r, x_val_r, y_test_r, y_val_r = train_test_split(x_test_r, y_test_r, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Set of Hyperparameters for Linear Regression are: Learning Rate =  0.091 Epochs =  700\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_min = -1\n",
    "r = []\n",
    "for learning_rate in range(10):\n",
    "    for epochs in range(100, 1000, 300):\n",
    "        lr = LinearRegression(learning_rate=0.001+learning_rate*0.01, epochs=epochs)\n",
    "        lr.fit(x_train_r, y_train_r)\n",
    "        r2 = r2_score(y_test_r, lr.predict(x_test_r))\n",
    "        if (r2 > r2_min):\n",
    "            r = [0.001+learning_rate*0.01, epochs]\n",
    "print(\"Best Performing Set of Hyperparameters for Linear Regression are: Learning Rate = \", r[0], \"Epochs = \", r[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note - Best performing set of Hyperparameters are hardcoded for each class when the object for that particular class is instantiated. In Case of MLPs and Logistic Regression, Best performing set of Hyperparamaters are taken from the previous assignment. #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Bagging ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5152838427947598\n",
      "0.43231441048034935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def bagging_1(model, num_estimators, sample_fraction, bootstrap, voting_mechanism):\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    predictions = np.zeros((x_test_c.shape[0], num_estimators))\n",
    "    labels, counts = np.unique(y_train_c, return_counts=True)\n",
    "    predicted_prob = np.zeros((num_estimators, x_test_c.shape[0], counts.shape[0]))\n",
    "\n",
    "\n",
    "    indices = np.arange(len(x_train_c))\n",
    "    len_init = len(x_train_c)\n",
    "\n",
    "    for i in range(num_estimators):\n",
    "\n",
    "        X = None\n",
    "        Y = None\n",
    "        index_l = np.random.choice(len(indices), int(len_init * sample_fraction), replace = bootstrap)\n",
    "        if (bootstrap is True):                     # perform sampling with replacement\n",
    "            X = x_train_c[index_l]\n",
    "            Y = y_train_c[index_l]\n",
    "        else:\n",
    "            X = x_train_c[index_l]\n",
    "            Y = y_train_c[index_l]\n",
    "            indices = np.delete(indices, index_l)\n",
    "\n",
    "\n",
    "        model.fit(X, Y)\n",
    "        if (isinstance(model, LogisticRegressionScratch)):\n",
    "            predictions[:, i] = model.predict(x_test_c, y_test_c)\n",
    "            if (model.y_pred.shape != (x_test_c.shape[0], 6)):\n",
    "                temp = np.zeros((x_test_c.shape[0], 6))\n",
    "                for j in range(model.y_pred.shape[1]):\n",
    "                    temp[:, j] = model.y_pred[:, j]\n",
    "                predicted_prob[i] = temp\n",
    "            else:\n",
    "                predicted_prob[i] = model.y_pred\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeClassifier)):\n",
    "            predictions[:, i] = model.predict(x_test_c)\n",
    "            for j in range(predictions.shape[0]):\n",
    "                predicted_prob[i, j, int(predictions[j, i])-3] = 1\n",
    "        \n",
    "        elif (isinstance(model, MLPClassification)):\n",
    "            predictions[:, i] = model.predict(x_test_c, y_test_c)\n",
    "            if (model.y_pred.shape != (x_test_c.shape[0], 6)):\n",
    "                temp = np.zeros((x_test_c.shape[0], 6))\n",
    "                for j in range(model.y_pred.shape[1]):\n",
    "                    temp[:, j] = model.y_pred[:, j]\n",
    "                predicted_prob[i] = temp\n",
    "            else:\n",
    "                predicted_prob[i] = model.y_pred\n",
    "\n",
    "    \n",
    "\n",
    "    outputs = np.zeros(y_test_c.shape[0])\n",
    "    for i in range(x_test_c.shape[0]):\n",
    "        if (voting_mechanism == 'hard'):\n",
    "            \n",
    "            votes = np.zeros(counts.shape[0])\n",
    "            for j in range(num_estimators):\n",
    "                votes[np.argmax(predicted_prob[j][i])] += 1\n",
    "            outputs[i] = np.argmax(votes)+3\n",
    "\n",
    "        else:\n",
    "            votes = np.zeros((counts.shape[0], counts.shape[0]))\n",
    "            for j in range(num_estimators):\n",
    "                votes[np.argmax(predicted_prob[j][i])] = predicted_prob[j][i]\n",
    "            sum_prob = np.sum(votes, axis = 0)\n",
    "            outputs[i] = np.argmax(sum_prob)+3\n",
    "\n",
    "    return accuracy_score(outputs, y_test_c)\n",
    "\n",
    "\n",
    "base_estimators = [LogisticRegressionScratch(learning_rate=0.091, threshold=0.5, epochs=700), DecisionTreeClassifier(), MLPClassification(learning_rate=0.071)]\n",
    "sample_fraction = 0.2\n",
    "bootstrap = True\n",
    "voting_mechanism = 'hard'\n",
    "\n",
    "for model in base_estimators:\n",
    "    accuracy = bagging_1(model, 3, sample_fraction, bootstrap, voting_mechanism)\n",
    "    print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "def bagging_2(model, num_estimators, sample_fraction, bootstrap, voting_mechanism):\n",
    "\n",
    "    predictions = np.zeros((x_test_r.shape[0], num_estimators))\n",
    "    labels, counts = np.unique(y_train_r, return_counts=True)\n",
    "    predicted_prob = np.zeros((num_estimators, x_test_r.shape[0]))\n",
    "\n",
    "    for i in range(num_estimators):\n",
    "\n",
    "        X = None\n",
    "        Y = None\n",
    "        if (bootstrap is True):                     # perform sampling with replacement\n",
    "            index_l = np.random.choice(len(x_train_r), int(len(x_train_r) * sample_fraction), replace = True)\n",
    "            X = x_train_r[index_l]\n",
    "            Y = y_train_r[index_l]\n",
    "        else:                                       # perform sampling without replacement\n",
    "            index_l = np.random.choice(len(x_train_r), int(len(x_train_r) * sample_fraction), replace = False)\n",
    "            X = x_train_r[index_l]\n",
    "            Y = y_train_r[index_l]\n",
    "\n",
    "        model.fit(X, Y)\n",
    "        if (isinstance(model, LinearRegression)):\n",
    "            predictions[:, i] = model.predict(x_test_r)\n",
    "            predicted_prob[i] = r2_score(y_val_r, model.predict(x_val_r))\n",
    "            # predicted_prob[i] = model.y_pred\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeRegressor)):\n",
    "            predictions[:, i] = model.predict(x_test_r)\n",
    "            predicted_prob[i] = r2_score(y_val_r, model.predict(x_val_r))\n",
    "            # for j in range(predictions.shape[0]):\n",
    "                # predicted_prob[i, j, int(predictions[j, i])-3] = 1\n",
    "        \n",
    "        elif (isinstance(model, MLPRegression)):\n",
    "            predictions[:, i] = model.predict(x_test_r, y_test_r)\n",
    "            predicted_prob[i] = r2_score(y_val_r, model.predict(x_val_r, y_val_r))\n",
    "            # predicted_prob[i] = model.y_pred\n",
    "\n",
    "\n",
    "    outputs = np.zeros(y_test_r.shape[0])\n",
    "    for i in range(x_test_r.shape[0]):\n",
    "        if (voting_mechanism == 'hard'):\n",
    "            outputs[i] = np.mean(predictions[i])\n",
    "\n",
    "        else:\n",
    "\n",
    "            sum = 0\n",
    "            sum_prob = 0\n",
    "            for j in range(num_estimators):\n",
    "                sum += predicted_prob[j][i]*predictions[i][j]\n",
    "                sum_prob += predicted_prob[j][i]\n",
    "            outputs[i] = sum / sum_prob\n",
    "\n",
    "    return r2_score(outputs, y_test_r)\n",
    "\n",
    "\n",
    "base_estimators = [LinearRegression(learning_rate=0.091, epochs=700), DecisionTreeRegressor(), MLPRegression(learning_rate=0.091)]\n",
    "sample_fraction = 1\n",
    "bootstrap = True\n",
    "voting_mechanism = 'soft'\n",
    "\n",
    "for model in base_estimators:\n",
    "    r2 = bagging_2(model, 3, sample_fraction, bootstrap, voting_mechanism)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for Bagging ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 False 3 hard\n",
      "0.15 False 3 soft\n",
      "0.15 False 5 hard\n",
      "0.15 False 5 soft\n",
      "0.15 True 3 hard\n",
      "0.15 True 3 soft\n",
      "0.15 True 5 hard\n",
      "0.15 True 5 soft\n",
      "0.25 False 3 hard\n",
      "0.25 False 3 soft\n",
      "0.25 True 3 hard\n",
      "0.25 True 3 soft\n",
      "0.15 False 3 hard\n",
      "0.15 False 3 soft\n",
      "0.15 False 5 hard\n",
      "0.15 False 5 soft\n",
      "0.15 True 3 hard\n",
      "0.15 True 3 soft\n",
      "0.15 True 5 hard\n",
      "0.15 True 5 soft\n",
      "0.25 False 3 hard\n",
      "0.25 False 3 soft\n",
      "0.25 True 3 hard\n",
      "0.25 True 3 soft\n",
      "0.15 False 3 hard\n",
      "0.15 False 3 soft\n",
      "0.15 False 5 hard\n",
      "0.15 False 5 soft\n",
      "0.15 True 3 hard\n",
      "0.15 True 3 soft\n",
      "0.15 True 5 hard\n",
      "0.15 True 5 soft\n",
      "0.25 False 3 hard\n",
      "0.25 False 3 soft\n",
      "0.25 True 3 hard\n",
      "0.25 True 3 soft\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "accuracies = []\n",
    "time_taken = []\n",
    "\n",
    "voting_mechanism = ['hard', 'soft']\n",
    "sample_fraction = [0.15, 0.25, 0.5, 0.75, 1]\n",
    "bootstrapping = [False, True]\n",
    "num_estimators = [3, 5, 7]\n",
    "base_model = [LogisticRegressionScratch(learning_rate=0.091, threshold=0.5, epochs=700), DecisionTreeClassifier(), MLPClassification(learning_rate=0.071)]\n",
    "\n",
    "for model in base_model:\n",
    "    for frac in sample_fraction:\n",
    "        for bootstrap in bootstrapping:\n",
    "            for n in num_estimators:\n",
    "                for vote in voting_mechanism:\n",
    "                    if (frac * n > 1):\n",
    "                        continue\n",
    "                    print(frac, bootstrap, n, vote)\n",
    "                    start_time = time.time()\n",
    "                    accuracy = bagging_1(model, n, frac, bootstrap, vote)\n",
    "                    \n",
    "                    if (isinstance(model, LogisticRegressionScratch)):\n",
    "                        accuracies.append([accuracy, frac, bootstrap, n, vote, \"Logistic\"])\n",
    "                    elif (isinstance(model, DecisionTreeClassifier)):\n",
    "                        accuracies.append([accuracy, frac, bootstrap, n, vote, \"DTree\"])\n",
    "                    elif (isinstance(model, MLPClassification)):\n",
    "                        accuracies.append([accuracy, frac, bootstrap, n, vote, \"MLP\"])\n",
    "                        \n",
    "                    end_time = time.time()\n",
    "                    time_taken.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Set of Hyperparameters are sample fraction =  0.15 Bootstrapping =  True Number of Estimators =  3 Voting Mechanism =  hard Model =  DTree\n"
     ]
    }
   ],
   "source": [
    "l = accuracies\n",
    "l.sort()\n",
    "print(\"Best Performing Set of Hyperparameters are sample fraction = \", l[-1][1], \"Bootstrapping = \", l[-1][2], \"Number of Estimators = \", l[-1][3], \"Voting Mechanism = \", l[-1][4], \"Model = \", l[-1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heat_map = []\n",
    "\n",
    "for model in base_model:\n",
    "    for frac in sample_fraction:\n",
    "        for n in num_estimators:\n",
    "            if (frac * n > 1):\n",
    "                continue\n",
    "\n",
    "            accuracy = bagging_1(model, n, frac, True, 'hard')\n",
    "            if (isinstance(model, LogisticRegressionScratch)):\n",
    "                heat_map.append([accuracy, frac, n, \"Logistic\"])\n",
    "            elif (isinstance(model, DecisionTreeClassifier)):\n",
    "                heat_map.append([accuracy, frac, n, \"DTree\"])\n",
    "            elif (isinstance(model, MLPClassification)):\n",
    "                heat_map.append([accuracy, frac, n, \"MLP\"])\n",
    "\n",
    "accuracy_matrix = [[], [], []]\n",
    "\n",
    "for i in range(len(heat_map)):\n",
    "    if (heat_map[i][3] == 'Logistic'):\n",
    "        accuracy_matrix[0].append(heat_map[i][0])\n",
    "    elif (heat_map[i][3] == 'DTree'):\n",
    "        accuracy_matrix[1].append(heat_map[i][0])\n",
    "    elif (heat_map[i][3] == 'MLP'):\n",
    "        accuracy_matrix[2].append(heat_map[i][0])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(accuracy_matrix, cmap='viridis', annot=True, fmt=\".3f\", xticklabels=[heat_map[i][2] for i in range(len(heat_map))], yticklabels=[heat_map[i][1] for i in range(len(heat_map))])\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Fraction of Samples')\n",
    "plt.title('Accuracy Heatmap for Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegressionScratch(learning_rate=0.091, threshold=0.5, epochs=700)\n",
    "clf.fit(x_train_c, y_train_c)\n",
    "a1 = accuracy_score(y_test_c, clf.predict(x_test_c, y_test_c))\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train_c, y_train_c)\n",
    "a2 = accuracy_score(y_test_c, clf.predict(x_test_c))\n",
    "\n",
    "\n",
    "clf = MLPClassification(learning_rate=0.071)\n",
    "clf.fit(x_train_c, y_train_c)\n",
    "clf.predict(x_test_c, y_test_c)\n",
    "y_pred = np.zeros(y_test_c.shape[0])\n",
    "for i in range(clf.y_pred.shape[0]):\n",
    "    y_pred[i] = np.argmax(clf.y_pred[i])\n",
    "a3 = accuracy_score(y_test_c, y_pred+3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = ['Logistic Regression', 'Decision Trees', 'Multi-Layer Perceptrons', 'Ensemble Model']\n",
    "counts = [a1, a2, a3, l[-1][0]]\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.bar(values, counts, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Histogram showing Accuracies of Four Distinct Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15 False 3 hard\n",
      "0.15 False 3 soft\n",
      "0.15 False 5 hard\n",
      "0.15 False 5 soft\n",
      "0.15 True 3 hard\n",
      "0.15 True 3 soft\n",
      "0.15 True 5 hard\n",
      "0.15 True 5 soft\n",
      "0.25 False 3 hard\n",
      "0.25 False 3 soft\n",
      "0.25 True 3 hard\n",
      "0.25 True 3 soft\n",
      "0.15 False 3 hard\n",
      "0.15 False 3 soft\n",
      "0.15 False 5 hard\n",
      "0.15 False 5 soft\n",
      "0.15 True 3 hard\n",
      "0.15 True 3 soft\n",
      "0.15 True 5 hard\n",
      "0.15 True 5 soft\n",
      "0.25 False 3 hard\n",
      "0.25 False 3 soft\n",
      "0.25 True 3 hard\n",
      "0.25 True 3 soft\n",
      "0.15 False 3 hard\n",
      "0.15 False 3 soft\n",
      "0.15 False 5 hard\n",
      "0.15 False 5 soft\n",
      "0.15 True 3 hard\n",
      "0.15 True 3 soft\n",
      "0.15 True 5 hard\n",
      "0.15 True 5 soft\n",
      "0.25 False 3 hard\n",
      "0.25 False 3 soft\n",
      "0.25 True 3 hard\n",
      "0.25 True 3 soft\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "r2 = []\n",
    "time_taken = []\n",
    "\n",
    "voting_mechanism = ['hard', 'soft']\n",
    "sample_fraction = [0.15, 0.25, 0.5, 0.75, 1]\n",
    "bootstrapping = [False, True]\n",
    "num_estimators = [3, 5, 7]\n",
    "base_model = [LinearRegression(learning_rate=0.091, epochs=700), DecisionTreeRegressor(), MLPRegression(learning_rate=0.091)]\n",
    "\n",
    "for model in base_model:\n",
    "    for frac in sample_fraction:\n",
    "        for bootstrap in bootstrapping:\n",
    "            for n in num_estimators:\n",
    "                for vote in voting_mechanism:\n",
    "                    if (frac * n > 1):\n",
    "                        continue\n",
    "                    print(frac, bootstrap, n, vote)\n",
    "                    start_time = time.time()\n",
    "                    r2_s = bagging_2(model, n, frac, bootstrap, vote)\n",
    "                    \n",
    "                    if (isinstance(model, LinearRegression)):\n",
    "                        r2.append([r2_s, frac, bootstrap, n, vote, \"Linear\"])\n",
    "                    elif (isinstance(model, DecisionTreeRegressor)):\n",
    "                        r2.append([r2_s, frac, bootstrap, n, vote, \"DTree\"])\n",
    "                    elif (isinstance(model, MLPRegression)):\n",
    "                        r2.append([r2_s, frac, bootstrap, n, vote, \"MLP\"])\n",
    "                        \n",
    "                    end_time = time.time()\n",
    "                    time_taken.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Set of Hyperparameters are sample fraction =  0.15 Bootstrapping =  False Number of Estimators =  5 Voting Mechanism =  soft Model =  DTree\n"
     ]
    }
   ],
   "source": [
    "l = r2\n",
    "l.sort()\n",
    "print(\"Best Performing Set of Hyperparameters are sample fraction = \", l[-1][1], \"Bootstrapping = \", l[-1][2], \"Number of Estimators = \", l[-1][3], \"Voting Mechanism = \", l[-1][4], \"Model = \", l[-1][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "heat_map = []\n",
    "\n",
    "for model in base_model:\n",
    "    for frac in sample_fraction:\n",
    "        for n in num_estimators:\n",
    "            if (frac * n > 1):\n",
    "                continue\n",
    "            \n",
    "            r2_s = bagging_2(model, n, frac, True, 'hard')\n",
    "            if (isinstance(model, LinearRegression)):\n",
    "                heat_map.append([r2_s, frac, n, \"Linear\"])\n",
    "            elif (isinstance(model, DecisionTreeRegressor)):\n",
    "                heat_map.append([r2_s, frac, n, \"DTree\"])\n",
    "            elif (isinstance(model, MLPRegression)):\n",
    "                heat_map.append([r2_s, frac, n, \"MLP\"])\n",
    "\n",
    "accuracy_matrix = [[], [], []]\n",
    "\n",
    "for i in range(len(heat_map)):\n",
    "    if (heat_map[i][3] == 'Linear'):\n",
    "        accuracy_matrix[0].append(heat_map[i][0])\n",
    "    elif (heat_map[i][3] == 'DTree'):\n",
    "        accuracy_matrix[1].append(heat_map[i][0])\n",
    "    elif (heat_map[i][3] == 'MLP'):\n",
    "        accuracy_matrix[2].append(heat_map[i][0])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(accuracy_matrix, cmap='viridis', annot=True, fmt=\".3f\", xticklabels=[heat_map[i][2] for i in range(len(heat_map))], yticklabels=[heat_map[i][1] for i in range(len(heat_map))])\n",
    "plt.xlabel('Number of Estimators')\n",
    "plt.ylabel('Fraction of Samples')\n",
    "plt.title('R2-Score Heatmap for Models')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LinearRegression(learning_rate=0.091, epochs=700)\n",
    "clf.fit(x_train_r, y_train_r)\n",
    "a1 = r2_score(y_test_r, clf.predict(x_test_r))\n",
    "\n",
    "\n",
    "clf = DecisionTreeRegressor()\n",
    "clf.fit(x_train_r, y_train_r)\n",
    "a2 = r2_score(y_test_r, clf.predict(x_test_r))\n",
    "\n",
    "\n",
    "clf = MLPRegression(learning_rate=0.071)\n",
    "clf.fit(x_train_r, y_train_r)\n",
    "\n",
    "a3 = r2_score(y_test_r, clf.predict(x_test_r, y_test_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.705698681118804 0.7395901926668984 -0.05745820870930829 0.8083645682090632\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "values = ['Logistic Regression', 'Decision Trees', 'Multi-Layer Perceptrons', 'Ensemble Model']\n",
    "counts = [a1, a2, a3, l[-1][0]]\n",
    "\n",
    "print(a1, a2, a3, l[-1][0])\n",
    "# Plotting the bar chart\n",
    "plt.bar(values, counts, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('R2-Scores')\n",
    "plt.title('Histogram showing R2-Scores of Four Distinct Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Stacking ## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5327510917030568"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stacking and Blending for Classification\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def stacking(n_folds, x_train, y, level_0_estimators, level_1_estimators):\n",
    "    kf = KFold(n_splits=n_folds, random_state=None)\n",
    "    le = LabelEncoder()\n",
    "    meta_features = np.zeros((len(y), len(level_0_estimators)))\n",
    "\n",
    "    for train_index, test_index in kf.split(x_train):\n",
    "\n",
    "        X_train, X_test = x_train[train_index], x_train[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        for i, model in enumerate(level_0_estimators):\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            if (isinstance(model, LogisticRegressionScratch)):\n",
    "                meta_features[test_index, i] = model.predict(X_test, y_test)\n",
    "\n",
    "            elif (isinstance(model, DecisionTreeClassifier)):\n",
    "                meta_features[test_index, i] = model.predict(X_test)\n",
    "            \n",
    "            elif (isinstance(model, MLPClassifier)):\n",
    "                meta_features[test_index, i] = model.predict(X_test)\n",
    "\n",
    "            \n",
    "\n",
    "    meta_features_test = np.zeros((y_test_c.shape[0], len(level_0_estimators)))\n",
    "    for i, model in enumerate(level_0_estimators):\n",
    "        if (isinstance(model, LogisticRegressionScratch)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_c, y_test_c)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeClassifier)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_c)\n",
    "        \n",
    "        elif (isinstance(model, MLPClassifier)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_c)\n",
    "\n",
    "\n",
    "\n",
    "    for model in level_1_estimators:\n",
    "        model.fit(meta_features, le.fit_transform(y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # retrain x_train, y_train on entire training dataset\n",
    "    for model in level_0_estimators:\n",
    "        model.fit(x_train, y)\n",
    "\n",
    "\n",
    "    # predict values of x_test_c on the base models \n",
    "    meta_train = np.zeros((x_test_c.shape[0], len(level_0_estimators)))\n",
    "    for i in range(len(level_0_estimators)):\n",
    "        if (isinstance(level_0_estimators[i], LogisticRegressionScratch)):\n",
    "            meta_train[:, i] = level_0_estimators[i].predict(x_test_c, y_test_c)\n",
    "\n",
    "        elif (isinstance(level_0_estimators[i], DecisionTreeClassifier)):\n",
    "            meta_train[:, i] = level_0_estimators[i].predict(x_test_c)\n",
    "        \n",
    "        elif (isinstance(level_0_estimators[i], MLPClassifier)):\n",
    "            meta_train[:, i] = level_0_estimators[i].predict(x_test_c)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = np.zeros(y_test_c.shape[0])\n",
    "    for model in level_1_estimators:\n",
    "\n",
    "        if (isinstance(model, LogisticRegressionScratch)):\n",
    "            y_pred = model.predict(meta_train, y_test_c)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeClassifier)):\n",
    "            y_pred = model.predict(meta_train)\n",
    "\n",
    "        # y_pred = model.predict(meta_train)\n",
    "        predictions += (y_pred / len(level_1_estimators))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        predictions[i] = int(predictions[i])\n",
    "    return accuracy_score(predictions, y_test_c)\n",
    "\n",
    "\n",
    "def blending(x_train, y, level_0_estimators, level_1_estimators):\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y, test_size=0.125, random_state=None)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    predictions = np.zeros((x_val.shape[0], len(level_0_estimators)))\n",
    "    for i in range(len(level_0_estimators)):\n",
    "        level_0_estimators[i].fit(x_train, y_train)\n",
    "\n",
    "        if (isinstance(level_0_estimators[i], LogisticRegressionScratch)):\n",
    "            y_pred = level_0_estimators[i].predict(x_val, y_val)\n",
    "\n",
    "        elif (isinstance(level_0_estimators[i], DecisionTreeClassifier)):\n",
    "            y_pred = level_0_estimators[i].predict(x_val)\n",
    "        \n",
    "        elif (isinstance(level_0_estimators[i], MLPClassifier)):\n",
    "            y_pred = level_0_estimators[i].predict(x_val)\n",
    "\n",
    "        # y_pred = level_0_estimators[i].predict(x_val)\n",
    "        predictions[:, i] = y_pred\n",
    "\n",
    "    meta_features_test = np.zeros((y_test_c.shape[0], len(level_0_estimators)))\n",
    "    for i, model in enumerate(level_0_estimators):\n",
    "\n",
    "        if (isinstance(model, LogisticRegressionScratch)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_c, y_test_c)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeClassifier)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_c)\n",
    "\n",
    "        elif (isinstance(model, MLPClassifier)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_c)\n",
    "\n",
    "\n",
    "\n",
    "    final_predictions = np.zeros(y_test_c.shape[0])\n",
    "    for model in level_1_estimators:\n",
    "        model.fit(predictions, le.fit_transform(y_val))\n",
    "\n",
    "        if (isinstance(model, LogisticRegressionScratch)):\n",
    "            pred = model.predict(meta_features_test, y_test_c)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeClassifier)):\n",
    "            pred = model.predict(meta_features_test)\n",
    "\n",
    "        final_predictions += (pred / len(level_1_estimators))\n",
    "\n",
    "    for i in range(final_predictions.shape[0]):\n",
    "        final_predictions[i] = int(final_predictions[i])\n",
    "\n",
    "    return accuracy_score(final_predictions, le.fit_transform(y_test_c))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stacking_classifier(level_0_estimators, level_1_estimators, stacking_methods):\n",
    "    if stacking_methods == 'Stacking':\n",
    "        a = stacking(10, x_train_c, y_train_c, level_0_estimators=level_0_estimators, level_1_estimators=level_1_estimators)\n",
    "        return a\n",
    "    else:\n",
    "        a = blending(x_train_c, y_train_c, level_0_estimators=level_0_estimators, level_1_estimators=level_1_estimators)\n",
    "        return a\n",
    "\n",
    "\n",
    "# level_0_estimators = [LogisticRegression(), DecisionTreeClassifier(), MLPClassifier()]\n",
    "# level_1_estimators = [LogisticRegression(), DecisionTreeClassifier()]\n",
    "\n",
    "level_0_estimators = [LogisticRegressionScratch(learning_rate=0.091, threshold=0.5, epochs=700), DecisionTreeClassifier(), MLPClassification(learning_rate=0.071)]\n",
    "level_1_estimators = [LogisticRegressionScratch(learning_rate=0.091, threshold=0.5, epochs=700), DecisionTreeClassifier()]\n",
    "# stacking_methods = 'Stacking'\n",
    "stacking_methods = 'Blending'\n",
    "stacking_classifier(level_0_estimators, level_1_estimators, stacking_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3031607283830425\n"
     ]
    }
   ],
   "source": [
    "# Stacking and Blending for Regression\n",
    "\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "def stacking_1(n_folds, x_train, y, level_0_estimators, level_1_estimators):\n",
    "    kf = KFold(n_splits=n_folds, random_state=None)\n",
    "    meta_features = np.zeros((len(y), len(level_0_estimators)))\n",
    "\n",
    "    for train_index, test_index in kf.split(x_train):\n",
    "\n",
    "        X_train, X_test = x_train[train_index], x_train[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        for i, model in enumerate(level_0_estimators):\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            if (isinstance(model, LinearRegression)):\n",
    "                meta_features[test_index, i] = model.predict(X_test)\n",
    "\n",
    "            elif (isinstance(model, DecisionTreeRegressor)):\n",
    "                meta_features[test_index, i] = model.predict(X_test)\n",
    "            \n",
    "            elif (isinstance(model, MLPRegressor)):\n",
    "                meta_features[test_index, i] = model.predict(X_test)\n",
    "\n",
    "            \n",
    "\n",
    "    meta_features_test = np.zeros((y_test_r.shape[0], len(level_0_estimators)))\n",
    "    for i, model in enumerate(level_0_estimators):\n",
    "        if (isinstance(model, LinearRegression)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_r)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeRegressor)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_r)\n",
    "        \n",
    "        elif (isinstance(model, MLPRegressor)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_r)\n",
    "\n",
    "\n",
    "\n",
    "    for model in level_1_estimators:\n",
    "        model.fit(meta_features, y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # retrain x_train, y_train on entire training dataset\n",
    "    for model in level_0_estimators:\n",
    "        model.fit(x_train, y)\n",
    "\n",
    "\n",
    "    # predict values of x_test_c on the base models \n",
    "    meta_train = np.zeros((x_test_r.shape[0], len(level_0_estimators)))\n",
    "    for i in range(len(level_0_estimators)):\n",
    "        if (isinstance(level_0_estimators[i], LinearRegression)):\n",
    "            meta_train[:, i] = level_0_estimators[i].predict(x_test_r)\n",
    "\n",
    "        elif (isinstance(level_0_estimators[i], DecisionTreeRegressor)):\n",
    "            meta_train[:, i] = level_0_estimators[i].predict(x_test_r)\n",
    "        \n",
    "        elif (isinstance(level_0_estimators[i], MLPRegressor)):\n",
    "            meta_train[:, i] = level_0_estimators[i].predict(x_test_r)\n",
    "\n",
    "\n",
    "\n",
    "    predictions = np.zeros(y_test_r.shape[0])\n",
    "    for model in level_1_estimators:\n",
    "\n",
    "        if (isinstance(model, LinearRegression)):\n",
    "            y_pred = model.predict(meta_train)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeRegressor)):\n",
    "            y_pred = model.predict(meta_train)\n",
    "\n",
    "        # y_pred = model.predict(meta_train)\n",
    "        predictions += (y_pred / len(level_1_estimators))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        predictions[i] = int(predictions[i])\n",
    "    print(mean_squared_error(predictions, y_test_r))\n",
    "    return\n",
    "\n",
    "\n",
    "def blending_1(x_train, y, level_0_estimators, level_1_estimators):\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y, test_size=0.125, random_state=None)\n",
    "\n",
    "    predictions = np.zeros((x_val.shape[0], len(level_0_estimators)))\n",
    "    for i in range(len(level_0_estimators)):\n",
    "        level_0_estimators[i].fit(x_train, y_train)\n",
    "\n",
    "        if (isinstance(level_0_estimators[i], LinearRegression)):\n",
    "            y_pred = level_0_estimators[i].predict(x_val)\n",
    "\n",
    "        elif (isinstance(level_0_estimators[i], DecisionTreeRegressor)):\n",
    "            y_pred = level_0_estimators[i].predict(x_val)\n",
    "        \n",
    "        elif (isinstance(level_0_estimators[i], MLPRegressor)):\n",
    "            y_pred = level_0_estimators[i].predict(x_val)\n",
    "\n",
    "        # y_pred = level_0_estimators[i].predict(x_val)\n",
    "        predictions[:, i] = y_pred\n",
    "\n",
    "    meta_features_test = np.zeros((y_test_r.shape[0], len(level_0_estimators)))\n",
    "    for i, model in enumerate(level_0_estimators):\n",
    "\n",
    "        if (isinstance(model, LinearRegression)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_r)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeRegressor)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_r)\n",
    "\n",
    "        elif (isinstance(model, MLPRegressor)):\n",
    "            meta_features_test[:, i] = model.predict(x_test_r)\n",
    "\n",
    "\n",
    "\n",
    "    final_predictions = np.zeros(y_test_r.shape[0])\n",
    "    for model in level_1_estimators:\n",
    "        model.fit(predictions, y_val)\n",
    "\n",
    "        if (isinstance(model, LinearRegression)):\n",
    "            pred = model.predict(meta_features_test)\n",
    "\n",
    "        elif (isinstance(model, DecisionTreeRegressor)):\n",
    "            pred = model.predict(meta_features_test)\n",
    "\n",
    "        final_predictions += (pred / len(level_1_estimators))\n",
    "\n",
    "    for i in range(final_predictions.shape[0]):\n",
    "        final_predictions[i] = int(final_predictions[i])\n",
    "\n",
    "    return r2_score(final_predictions, y_test_r)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stacking_regressor(level_0_estimators, level_1_estimators, stacking_methods):\n",
    "    if stacking_methods == 'Stacking':\n",
    "        return stacking_1(10, x_train_r, y_train_r, level_0_estimators=level_0_estimators, level_1_estimators=level_1_estimators)\n",
    "    else:\n",
    "        return blending_1(x_train_r, y_train_r, level_0_estimators=level_0_estimators, level_1_estimators=level_1_estimators)\n",
    "\n",
    "\n",
    "# level_0_estimators = [LogisticRegression(), DecisionTreeClassifier(), MLPClassifier()]\n",
    "# level_1_estimators = [LogisticRegression(), DecisionTreeClassifier()]\n",
    "level_0_estimators = [LinearRegression(learning_rate=0.091, epochs=700), DecisionTreeRegressor(), MLPRegression(learning_rate=0.091)]\n",
    "level_1_estimators = [LinearRegression(learning_rate=0.091, epochs=700), DecisionTreeRegressor()]\n",
    "stacking_methods = 'Stacking'\n",
    "# stacking_methods = 'Blending'\n",
    "stacking_regressor(level_0_estimators, level_1_estimators, stacking_methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for Stacking ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "accuracies = []\n",
    "time_taken = []\n",
    "\n",
    "stacking_methods = ['Stacking', 'Blending']\n",
    "\n",
    "for meth in stacking_methods:\n",
    "    start_time = time.time()\n",
    "    accuracy = stacking_classifier(level_0_estimators, level_1_estimators, stacking_methods)\n",
    "    \n",
    "    if (meth == 'Stacking'):\n",
    "        accuracies.append([accuracy, \"Stacking\"])\n",
    "    elif (meth == 'Blending'):\n",
    "        accuracies.append([accuracy, \"Blending\"])\n",
    "                \n",
    "    end_time = time.time()\n",
    "    time_taken.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Set of Hyperparameter is Stacking Methodology =  Blending\n",
      "[[0.40611353711790393, 'Stacking'], [0.4104803493449782, 'Blending']]\n"
     ]
    }
   ],
   "source": [
    "l = accuracies\n",
    "l.sort()\n",
    "print(\"Best Performing Set of Hyperparameter is Stacking Methodology = \", l[-1][1])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Stacking Ensemble =  0.4104803493449782 and Accuracy of Bagging Ensemble =  0.4672489082969432\n",
      "Time Taken by Stacking Ensemble =  1.1399266719818115 and that by Bagging Ensemble =  0.684990406036377\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "base_estimators = [LogisticRegressionScratch(learning_rate=0.091, threshold=0.5, epochs=700), DecisionTreeClassifier(), MLPClassification(learning_rate=0.071)]\n",
    "start_time_bagging = time.time()\n",
    "\n",
    "accuracy_bagging = -1\n",
    "for model in base_estimators:\n",
    "    accuracy_bagging = max(accuracy_bagging, bagging_1(model, 3, sample_fraction = 0.15, bootstrap = True, voting_mechanism = 'hard'))\n",
    "end_time_bagging = time.time()\n",
    "\n",
    "print(\"Accuracy of Stacking Ensemble = \", l[-1][0], \"and Accuracy of Bagging Ensemble = \", accuracy_bagging)\n",
    "print(\"Time Taken by Stacking Ensemble = \", time_taken[0], \"and that by Bagging Ensemble = \", end_time_bagging-start_time_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "r2 = []\n",
    "time_taken = []\n",
    "\n",
    "level_0_estimators = [LinearRegression(learning_rate=0.091, epochs=700), DecisionTreeRegressor(), MLPRegression(learning_rate=0.091)]\n",
    "level_1_estimators = [LinearRegression(learning_rate=0.091, epochs=700), DecisionTreeRegressor()]\n",
    "\n",
    "stacking_methods = ['Stacking', 'Blending']\n",
    "\n",
    "for meth in stacking_methods:\n",
    "    start_time = time.time()\n",
    "    r2_s = stacking_regressor(level_0_estimators, level_1_estimators, stacking_methods)\n",
    "    \n",
    "    if (meth == 'Stacking'):\n",
    "        r2.append([r2_s, \"Stacking\"])\n",
    "    elif (meth == 'Blending'):\n",
    "        r2.append([r2_s, \"Blending\"])\n",
    "                \n",
    "    end_time = time.time()\n",
    "    time_taken.append(end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Performing Set of Hyperparameter is Stacking Methodology =  Stacking\n",
      "[[-6.465723452430349, 'Blending'], [0.48857111341649484, 'Stacking']]\n"
     ]
    }
   ],
   "source": [
    "l = r2\n",
    "l.sort()\n",
    "print(\"Best Performing Set of Hyperparameter is Stacking Methodology = \", l[-1][1])\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2-Score of Stacking Ensemble =  0.48857111341649484 and R2-Score of Bagging Ensemble =  0.6258193288196434\n",
      "Time Taken by Stacking Ensemble =  1.5726172924041748 and that by Bagging Ensemble =  0.9382250308990479\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "base_estimators = [LinearRegression(learning_rate=0.091, epochs=700), DecisionTreeRegressor(), MLPRegression(learning_rate=0.091)]\n",
    "start_time_bagging = time.time()\n",
    "\n",
    "r2_bagging = -1\n",
    "for model in base_estimators:\n",
    "    r2_bagging = max(r2_bagging, bagging_2(model, 3, sample_fraction = 0.15, bootstrap = True, voting_mechanism = 'hard'))\n",
    "end_time_bagging = time.time()\n",
    "\n",
    "print(\"R2-Score of Stacking Ensemble = \", l[-1][0], \"and R2-Score of Bagging Ensemble = \", r2_bagging)\n",
    "print(\"Time Taken by Stacking Ensemble = \", time_taken[0], \"and that by Bagging Ensemble = \", end_time_bagging-start_time_bagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Random Forest vs Boosted Trees ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classification = pd.read_csv('./WineQT.csv')\n",
    "data_classification = data_classification.drop(columns=['Id'])\n",
    "l = [i for i in data_classification]\n",
    "data_classification = data_classification.dropna()\n",
    "data_classification = np.array([data_classification])\n",
    "data_classification = data_classification[0]\n",
    "\n",
    "X = np.zeros((data_classification.shape[0], data_classification.shape[1]-1))\n",
    "for i in range(data_classification.shape[1]-1):\n",
    "    X[:, i] = data_classification[:, i]\n",
    "y = data_classification[:, data_classification.shape[1]-1]\n",
    "x_train_c, x_test_c, y_train_c, y_test_c = train_test_split(X, y, test_size=0.3)\n",
    "x_test_c, x_val_c, y_test_c, y_val_c = train_test_split(x_test_c, y_test_c, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forests ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7685589519650655\n"
     ]
    }
   ],
   "source": [
    "# Random Forests for Classification\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Random Forest Classifier (generated from ChatGPT)\n",
    "class RandomForestClassifier:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = [DecisionTreeClassifier(max_depth=self.max_depth, random_state=1) for _ in range(self.n_estimators)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for tree in self.forest:\n",
    "            random_indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            tree.fit(X[random_indices], y[random_indices])\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.forest])\n",
    "        return [Counter(pred).most_common(1)[0][0] for pred in predictions.T]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "\n",
    "for i in range(y_train_c.shape[0]):\n",
    "    if y_train_c[i] == 3 or y_train_c[i] == 4 or y_train_c[i] == 5:\n",
    "        y_train_c[i] = 0\n",
    "    elif y_train_c[i] == 6 or y_train_c[i] == 7 or y_train_c[i] == 8:\n",
    "        y_train_c[i] = 1\n",
    "\n",
    "for i in range(y_test_c.shape[0]):\n",
    "    if y_test_c[i] == 3 or y_test_c[i] == 4 or y_test_c[i] == 5:\n",
    "        y_test_c[i] = 0\n",
    "    elif y_test_c[i] == 6 or y_test_c[i] == 7 or y_test_c[i] == 8:\n",
    "        y_test_c[i] = 1\n",
    "\n",
    "le = LabelEncoder()\n",
    "clf.fit(x_train_c, le.fit_transform(y_train_c))\n",
    "predictions = clf.predict(x_test_c)\n",
    "print(\"Accuracy = \", accuracy_score(le.fit_transform(y_test_c), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8217145691396008"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forests for Regression\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Random Forest (generated from ChatGPT)\n",
    "class RandomForestRegressor:\n",
    "    def __init__(self, n_estimators=100, max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.forest = [DecisionTreeRegressor(max_depth=self.max_depth, random_state=1) for _ in range(self.n_estimators)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for tree in self.forest:\n",
    "            random_indices = np.random.choice(len(X), len(X), replace=True)\n",
    "            tree.fit(X[random_indices], y[random_indices])\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.array([tree.predict(X) for tree in self.forest])\n",
    "        return [Counter(pred).most_common(1)[0][0] for pred in predictions.T]\n",
    "\n",
    "clf = RandomForestRegressor()\n",
    "\n",
    "clf.fit(x_train_r, y_train_r)\n",
    "predictions = clf.predict(x_test_r)\n",
    "r2_score(y_test_r, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for Random Forests ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7685589519650655, 100, 0.30564379692077637], [0.7816593886462883, 1000, 0.32067179679870605], [0.7860262008733624, 1, 0.3067452907562256], [0.7903930131004366, 10, 0.29851317405700684]]\n",
      "Best Performing Set of Hyperparameter is Number of Estimators =  10 And Running Time =  0.29851317405700684\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_estimators = [1, 10, 100, 1000]\n",
    "accuracies = []\n",
    "for n in num_estimators:\n",
    "    start_time = time.time()\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(x_train_c, y_train_c)\n",
    "    predictions = clf.predict(x_test_c)\n",
    "    a = accuracy_score(y_test_c, predictions)\n",
    "    end_time = time.time()\n",
    "    accuracies.append([a, n, end_time-start_time])\n",
    "accuracies.sort()\n",
    "print(accuracies)\n",
    "print(\"Best Performing Set of Hyperparameter is Number of Estimators = \", accuracies[-1][1], \"And Running Time = \", accuracies[-1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.737004792576365, 1, 0.18271541595458984], [0.7837365587535958, 100, 0.16941404342651367], [0.8090579804310968, 1000, 0.17628812789916992], [0.8203163425600266, 10, 0.17351889610290527]]\n",
      "Best Performing Set of Hyperparameter is Number of Estimators =  10 and Running Time =  0.17351889610290527\n"
     ]
    }
   ],
   "source": [
    "num_estimators = [1, 10, 100, 1000]\n",
    "r2 = []\n",
    "for n in num_estimators:\n",
    "    start_time = time.time()\n",
    "    clf = RandomForestRegressor()\n",
    "    clf.fit(x_train_r, y_train_r)\n",
    "    predictions = clf.predict(x_test_r)\n",
    "    r2_s = r2_score(y_test_r, predictions)\n",
    "    end_time = time.time()\n",
    "    r2.append([r2_s, n, end_time-start_time])\n",
    "r2.sort()\n",
    "print(r2)\n",
    "print(\"Best Performing Set of Hyperparameter is Number of Estimators = \", r2[-1][1], \"and Running Time = \", r2[-1][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292576419213974"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost Classifier for Classication\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class AdaBoostClassifier:\n",
    "    def __init__(self, n_estimators, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.n_estimators = n_estimators\n",
    "        return\n",
    "    \n",
    "\n",
    "    def initialize(self, x_train):\n",
    "        x = np.zeros(x_train.shape[0])\n",
    "        x += 1 / x_train.shape[0]\n",
    "        self.weights = x\n",
    "        return\n",
    "    \n",
    "\n",
    "    def update_weights(self, clf, alpha, x_train, y_train):\n",
    "        le = LabelEncoder()\n",
    "        y = y_train\n",
    "        le.fit_transform(y)\n",
    "        self.weights = np.multiply(self.weights, np.exp(-alpha * np.multiply(y, clf.predict(x_train))))\n",
    "        self.weights /= np.sum(self.weights)\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.initialize(x_train)\n",
    "        self.classifiers = []\n",
    "        self.alphas = []\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            le = LabelEncoder()\n",
    "            clf = DecisionTreeClassifier(criterion='gini', max_depth=self.max_depth, random_state=None)\n",
    "            clf.fit(x_train, le.fit_transform(y_train), sample_weight=self.weights)\n",
    "            error = np.sum(self.weights * (np.not_equal(y_train, clf.predict(x_train))).astype(int)) / np.sum(self.weights)\n",
    "            # error = (np.sum(self.weights * (np.not_equal(le.fit_transform(y_train), clf.predict(x_train))).astype(int))) / np.sum(self.weights)\n",
    "\n",
    "\n",
    "            epsilon = 1e-3\n",
    "            alpha = np.log((1 - error + epsilon) / (error + epsilon))\n",
    "            self.classifiers.append(clf)\n",
    "            self.alphas.append(alpha)\n",
    "            self.update_weights(clf, alpha, x_train, y_train)\n",
    "        return\n",
    "\n",
    "\n",
    "    def predict(self, x_test, y_test):\n",
    "        final_predictions = np.zeros(x_test.shape[0])\n",
    "        for i in range(len(self.classifiers)):\n",
    "            predictions = self.classifiers[i].predict(x_test)\n",
    "            final_predictions += predictions * self.alphas[i]\n",
    "\n",
    "        return np.sign(final_predictions)\n",
    "\n",
    "\n",
    "for i in range(y_train_c.shape[0]):\n",
    "    if y_train_c[i] == 3 or y_train_c[i] == 4 or y_train_c[i] == 5:\n",
    "        # y_train_c[i] = 0\n",
    "        y_train_c[i] = -1\n",
    "    elif y_train_c[i] == 6 or y_train_c[i] == 7 or y_train_c[i] == 8:\n",
    "        y_train_c[i] = 1\n",
    "\n",
    "for i in range(y_test_c.shape[0]):\n",
    "    if y_test_c[i] == 3 or y_test_c[i] == 4 or y_test_c[i] == 5:\n",
    "        # y_test_c[i] = 0\n",
    "        y_test_c[i] = -1\n",
    "    elif y_test_c[i] == 6 or y_test_c[i] == 7 or y_test_c[i] == 8:\n",
    "        y_test_c[i] = 1\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=10, max_depth=5)\n",
    "clf.fit(x_train_c, y_train_c)\n",
    "predictions = clf.predict(x_test_c, y_test_c)\n",
    "\n",
    "for i in range(predictions.shape[0]):\n",
    "    if predictions[i] == 3 or predictions[i] == 4 or predictions[i] == 5:\n",
    "        predictions[i] = 0\n",
    "    elif predictions[i] == 6 or predictions[i] == 7 or predictions[i] == 8:\n",
    "        predictions[i] = 1\n",
    "\n",
    "accuracy_score(y_test_c, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522809893426037"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdaBoost Regressor for Regression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "def weighted_median(values, weights):      # algorithm and code referred from https://dafriedman97.github.io/mlbook/content/c6/s2/boosting.html\n",
    "    sorted_indices = values.argsort()\n",
    "    values = values[sorted_indices]\n",
    "    weights = weights[sorted_indices]\n",
    "    weights_cumulative_sum = weights.cumsum()\n",
    "    median_weight = np.argmax(weights_cumulative_sum >= sum(weights)/2)\n",
    "    return values[median_weight]\n",
    "\n",
    "\n",
    "class AdaBoostRegressor:\n",
    "    def __init__(self, n_estimators, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.n_estimators = n_estimators\n",
    "        return\n",
    "    \n",
    "\n",
    "    def initialize(self, x_train):\n",
    "        x = np.zeros(x_train.shape[0])\n",
    "        x += 1 / x_train.shape[0]\n",
    "        self.weights = x\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.initialize(x_train)\n",
    "        self.regressors = []\n",
    "        self.betas = []\n",
    "        pred_train = np.zeros((x_train.shape[0], self.n_estimators))\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            indices = np.random.choice(np.arange(x_train.shape[0]), size = x_train.shape[0], replace = True, p = self.weights)\n",
    "            x = x_train[indices]\n",
    "            y = y_train[indices]\n",
    "\n",
    "            clf = DecisionTreeRegressor(max_depth=self.max_depth)\n",
    "            clf.fit(x, y, sample_weight=self.weights)\n",
    "            yhat = clf.predict(x_train)\n",
    "            pred_train[:, i] = yhat\n",
    "            self.regressors.append(clf)\n",
    "            \n",
    "            temp = np.abs(y_train-yhat)\n",
    "            observation_error = temp / np.max(temp)\n",
    "            \n",
    "            model_error = np.sum(self.weights*observation_error)\n",
    "            if model_error >= 0.5:\n",
    "                self.n_estimators = i-1\n",
    "                pred_train = pred_train[:,:i-1]\n",
    "                self.regressors = self.regressors[:i-1]\n",
    "                break\n",
    "            \n",
    "            beta = model_error / (1 - model_error)\n",
    "            self.betas.append(beta)\n",
    "            self.weights = self.weights * (beta ** (1-observation_error) / np.sum(self.weights * beta ** (1-observation_error)))\n",
    "\n",
    "        self.weights = np.log(1 / np.array(self.betas))\n",
    "        return\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        predictions = np.zeros((x_test.shape[0], self.n_estimators))\n",
    "        for i in range(len(self.regressors)):\n",
    "            predictions[:,i] = self.regressors[i].predict(x_test)\n",
    "        return np.array([weighted_median(predictions[i], self.weights) for i in range(x_test.shape[0])]) \n",
    "\n",
    "\n",
    "\n",
    "clf = AdaBoostRegressor(n_estimators=10, max_depth=None)\n",
    "clf.fit(x_train_r, y_train_r)\n",
    "predictions = clf.predict(x_test_r)\n",
    "mse = np.sum(np.square(predictions-y_test_r)) / predictions.shape[0]\n",
    "r2_score(y_test_r, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter Tuning for AdaBoost ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.611353711790393, 100, 7, 0.18640828132629395], [0.6200873362445415, 1000, 7, 1.2675950527191162], [0.6637554585152838, 1000, 5, 1.4615144729614258], [0.6681222707423581, 100, 5, 0.22249650955200195], [0.6812227074235808, 1, 1, 0.0033965110778808594], [0.6855895196506551, 1, 3, 0.002769947052001953], [0.6986899563318777, 10, 3, 0.02324700355529785], [0.6986899563318777, 10, 7, 0.031639814376831055], [0.6986899563318777, 100, 3, 0.16488051414489746], [0.6986899563318777, 1000, 3, 1.6311299800872803], [0.7030567685589519, 1, 7, 0.005182504653930664], [0.7030567685589519, 10, 1, 0.014478206634521484], [0.7030567685589519, 100, 1, 0.09226655960083008], [0.7030567685589519, 1000, 1, 0.9174680709838867], [0.7292576419213974, 1, 5, 0.00384521484375], [0.7336244541484717, 10, 5, 0.02628636360168457]]\n",
      "Best Performing Set of Hyperparameter is Number of Estimators =  10 and Max Depth =  5 and Running Time =  5\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_estimators = [1, 10, 100, 1000]\n",
    "max_depth = [1, 3, 5, 7]\n",
    "accuracies = []\n",
    "for n in num_estimators:\n",
    "    for depth in max_depth:\n",
    "        start_time = time.time()\n",
    "        clf = AdaBoostClassifier(max_depth=depth, n_estimators=n)\n",
    "        clf.fit(x_train_c, y_train_c)\n",
    "        predictions = clf.predict(x_test_c, y_test_c)\n",
    "        a = accuracy_score(y_test_c, predictions)\n",
    "        end_time = time.time()\n",
    "        accuracies.append([a, n, depth, end_time-start_time])\n",
    "accuracies.sort()\n",
    "print(accuracies)\n",
    "print(\"Best Performing Set of Hyperparameter is Number of Estimators = \", accuracies[-1][1], \"and Max Depth = \", accuracies[-1][2], \"and Running Time = \", accuracies[-1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.203482021181826, 10, 1, 0.0067865848541259766], [0.4755517467370679, 100, 1, 0.011237859725952148], [0.5004938175852984, 1, 1, 0.0034301280975341797], [0.5372220211573855, 1, 7, 0.0023756027221679688], [0.5645978892723549, 1000, 1, 0.0162656307220459], [0.710573944068446, 1, 5, 0.0026144981384277344], [0.7286666874676038, 1, 3, 0.001726388931274414], [0.8399926539751865, 10, 3, 0.009805917739868164], [0.852069991803748, 10, 5, 0.01468205451965332], [0.8560832936134919, 10, 7, 0.017852067947387695], [0.8616534949880986, 100, 3, 0.06759142875671387], [0.8637707991452092, 1000, 3, 0.636638879776001], [0.884298686285106, 1000, 5, 0.9304718971252441], [0.8869204245694099, 100, 5, 0.09435200691223145], [0.8936352312195623, 100, 7, 0.1251201629638672], [0.8956928337041368, 1000, 7, 1.2584340572357178]]\n",
      "Best Performing Set of Hyperparameter is Number of Estimators =  1000 and Max Depth =  7 and Running Time =  1.2584340572357178\n"
     ]
    }
   ],
   "source": [
    "num_estimators = [1, 10, 100, 1000]\n",
    "max_depth = [1, 3, 5, 7]\n",
    "r2 = []\n",
    "for n in num_estimators:\n",
    "    for depth in max_depth:\n",
    "        start_time = time.time()\n",
    "        clf = AdaBoostRegressor(max_depth=depth, n_estimators=n)\n",
    "        clf.fit(x_train_r, y_train_r)\n",
    "        predictions = clf.predict(x_test_r)\n",
    "        r2_s = r2_score(y_test_r, predictions)\n",
    "        end_time = time.time()\n",
    "        r2.append([r2_s, n, depth, end_time-start_time])\n",
    "r2.sort()\n",
    "print(r2)\n",
    "print(\"Best Performing Set of Hyperparameter is Number of Estimators = \", r2[-1][1], \"and Max Depth = \", r2[-1][2], \"and Running Time = \", r2[-1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosted Trees ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.7467248908296943\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting for Classification\n",
    "\n",
    "\n",
    "class GradientBoostClassifier:\n",
    "    def __init__(self, learning_rate, n_estimators):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        return\n",
    "    \n",
    "\n",
    "    def initialize(self, y_train):\n",
    "        a = np.where(y_train == 0)[0].shape[0]\n",
    "        self.log_odds = np.log((y_train.shape[0]-a) / a)\n",
    "        self.predicted_prob = (y_train.shape[0]-a) / y_train.shape[0]\n",
    "        return\n",
    "    \n",
    "    \n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.initialize(y_train)\n",
    "        self.classifiers = []\n",
    "        self.initial_log_odds = self.log_odds\n",
    "\n",
    "        for _ in range(self.n_estimators):\n",
    "            r = y_train-self.predicted_prob\n",
    "            tree = DecisionTreeClassifier(random_state=42)\n",
    "            le = LabelEncoder()\n",
    "            tree.fit(x_train, le.fit_transform(r))\n",
    "            epsilon = 1e-5                      # numerical stability\n",
    "            outputs_leaf = np.sum(tree.predict(x_train)) / np.sum(self.predicted_prob * (1-self.predicted_prob)+epsilon)\n",
    "            self.log_odds = self.log_odds + self.learning_rate * outputs_leaf\n",
    "            self.predicted_prob = 1 / (1+np.exp(-self.log_odds))\n",
    "            self.classifiers.append(tree)\n",
    "        return\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        pred = np.zeros(x_test.shape[0])\n",
    "        record = self.initial_log_odds + self.learning_rate * np.sum([tree.predict(x_test) for tree in self.classifiers], axis=0)\n",
    "        indices = np.where(record >= 0.5)\n",
    "        pred[indices] = 1\n",
    "        return pred\n",
    "\n",
    "\n",
    "for i in range(y_train_c.shape[0]):\n",
    "    if y_train_c[i] == 3 or y_train_c[i] == 4 or y_train_c[i] == 5:\n",
    "        y_train_c[i] = 0\n",
    "    elif y_train_c[i] == 6 or y_train_c[i] == 7 or y_train_c[i] == 8:\n",
    "        y_train_c[i] = 1\n",
    "\n",
    "for i in range(y_test_c.shape[0]):\n",
    "    if y_test_c[i] == 3 or y_test_c[i] == 4 or y_test_c[i] == 5:\n",
    "        y_test_c[i] = 0\n",
    "    elif y_test_c[i] == 6 or y_test_c[i] == 7 or y_test_c[i] == 8:\n",
    "        y_test_c[i] = 1\n",
    "\n",
    "\n",
    "clf = GradientBoostClassifier(learning_rate=0.1, n_estimators=100)\n",
    "clf.fit(x_train_c, y_train_c)\n",
    "predictions = clf.predict(x_test_c)\n",
    "print(\"Accuracy = \", accuracy_score(le.fit_transform(y_test_c), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.751656976415612"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gradient Boosting for Regression\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "\n",
    "class GradientBoostRegressor:\n",
    "    def __init__(self, learning_rate, n_estimators):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        return\n",
    "    \n",
    "\n",
    "    def initialize(self, y_train):\n",
    "        x = np.zeros(y_train.shape[0])\n",
    "        x += np.mean(y_train)\n",
    "        self.predictions = x\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.initialize(y_train)\n",
    "        self.classifiers = []\n",
    "        self.initial_mean = np.mean(y_train)\n",
    "\n",
    "        for _ in range(1000):\n",
    "            r = y_train-self.predictions\n",
    "            tree = DecisionTreeRegressor(random_state=1)\n",
    "            tree.fit(x_train, r)\n",
    "            self.predictions += self.learning_rate * tree.predict(x_train)\n",
    "            self.classifiers.append(tree)\n",
    "        return\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.initial_mean + self.learning_rate * np.sum([tree.predict(x_test) for tree in self.classifiers], axis=0)\n",
    "\n",
    "\n",
    "clf = GradientBoostRegressor(learning_rate=0.1, n_estimators=100)\n",
    "clf.fit(x_train_r, y_train_r)\n",
    "predictions = clf.predict(x_test_r)\n",
    "# mean = np.mean(predictions)\n",
    "# std = np.std(predictions)\n",
    "# predictions = (predictions-mean)/std\n",
    "mse = np.sum(np.square(predictions-y_test_r)) / predictions.shape[0]\n",
    "# print(\"MSE = \", mse)\n",
    "r2_score(y_test_r, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparamater Tuning for Gradient Boosted Trees ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45414847161572053, 1, 0.1, 0.007980108261108398], [0.45414847161572053, 1, 0.2, 0.005274534225463867], [0.7467248908296943, 10, 0.1, 0.04267621040344238], [0.7467248908296943, 10, 0.2, 0.03815293312072754], [0.7467248908296943, 100, 0.1, 0.3834812641143799], [0.7467248908296943, 100, 0.2, 0.36548829078674316], [0.7467248908296943, 1000, 0.1, 3.5981905460357666], [0.7467248908296943, 1000, 0.2, 3.667839765548706]]\n",
      "Best Performing Set of Hyperparameter is Number of Estimators =  1000 and Learning Rate =  0.2 and Running Time =  3.667839765548706\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "num_estimators = [1, 10, 100, 1000]\n",
    "learning_rate = [0.1, 0.2]\n",
    "accuracies = []\n",
    "for n in num_estimators:\n",
    "    for lr in learning_rate:\n",
    "        start_time = time.time()\n",
    "        clf = GradientBoostClassifier(n_estimators=n, learning_rate=lr)\n",
    "        clf.fit(x_train_c, y_train_c)\n",
    "        predictions = clf.predict(x_test_c)\n",
    "        a = accuracy_score(y_test_c, predictions)\n",
    "        end_time = time.time()\n",
    "        accuracies.append([a, n, lr, end_time-start_time])\n",
    "accuracies.sort()\n",
    "print(accuracies)\n",
    "print(\"Best Performing Set of Hyperparameter is Number of Estimators = \", accuracies[-1][1], \"and Learning Rate = \", accuracies[-1][2], \"and Running Time = \", accuracies[-1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.751656976415612, 1, 0.1, 0.6717760562896729], [0.751656976415612, 10, 0.1, 0.6727848052978516], [0.751656976415612, 100, 0.1, 0.6756391525268555], [0.751656976415612, 1000, 0.1, 0.7057430744171143], [0.7594530983199593, 1, 0.2, 0.49207067489624023], [0.7594530983199593, 10, 0.2, 0.48839664459228516], [0.7594530983199593, 100, 0.2, 0.5044534206390381], [0.7594530983199593, 1000, 0.2, 0.5032241344451904]]\n",
      "Best Performing Set of Hyperparameter is Number of Estimators =  1000 and Learning Rate =  0.2 and Running Time =  0.5032241344451904\n"
     ]
    }
   ],
   "source": [
    "num_estimators = [1, 10, 100, 1000]\n",
    "learning_rate = [0.1, 0.2]\n",
    "r2 = []\n",
    "for n in num_estimators:\n",
    "    for lr in learning_rate:\n",
    "        start_time = time.time()\n",
    "        clf = GradientBoostRegressor(n_estimators=n, learning_rate=lr)\n",
    "        clf.fit(x_train_r, y_train_r)\n",
    "        predictions = clf.predict(x_test_r)\n",
    "        r2_s = r2_score(y_test_r, predictions)\n",
    "        end_time = time.time()\n",
    "        r2.append([r2_s, n, lr, end_time-start_time])\n",
    "r2.sort()\n",
    "print(r2)\n",
    "print(\"Best Performing Set of Hyperparameter is Number of Estimators = \", r2[-1][1], \"and Learning Rate = \", r2[-1][2], \"and Running Time = \", r2[-1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison and Analysis:**\n",
    "Random Forest generally performs well in terms of accuracy and R2 score.\n",
    "AdaBoost and Gradient Boosted Trees show competitive performance, but their training times are higher compared to Random Forest.\n",
    "For AdaBoost Classification, lower learning rates seem to perform better.\n",
    "Gradient Boosted Trees tend to perform better with a higher number of estimators and lower learning rates.\n",
    "AdaBoost Regression and Gradient Boosted Trees Regression show significant improvement over Random Forest Regression in terms of R2 score.\n",
    "\n",
    "**Analysis of Mistakes and Feature Similarity**\n",
    "We can see that more or less, all the above methods provide the same Accuracies/R2-Scores. So, we can use any of them for classification/regression tasks. Also, we note that all of them use Decision Trees as their basic classifier/regressor model. So, the root cause behind the comparable performance of these algorithms is due to the fact that Decision Trees is being used for their implementation. Some of the Limitations include bias towards Dominant Classes in Classification Tasks(it greatly favours the Dominant Classes in the Dataset and the predictions of Classes with lower frequency is many a times that of Dominant Classes, thus suppressing their say in the final output and therefore leading to misclassified samples) and its Greedy Nature (in the way that it always chooses the Local Optimal Decisions which may not be well suited for Global Optimality). Decision Trees are also sensitive to outliers. Also, in regression tasks, where the predictions are continuous, Decision Trees Predictions might revolve around the Standard Centrality Measures (Mean, Median, Mode) and thus, are penalised to some extent when it sees outliers in the data. Because the Datasets are same for all 3 tasks, we note that there are similarities across all features in these models, and thus more or less the correlations between all the 3 models are same and thus common predictions are being reported by Decision Tree in the 3 Methodologies, which are captured by comparing the R2-Scores and Accuracies of the Models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
